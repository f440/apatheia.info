<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>apatheia.info</title>
  <link href="http://apatheia.info/"/>
  <link href="http://apatheia.info/atom.xml" rel="self"/>
  <updated>2013-06-17T09:13:00Z</updated>
  <id>http://apatheia.info/</id>
  <author>
    <name>f440</name>
  </author>
  <entry>
    <title>仮想環境構築に docker を使う</title>
    <link rel="alternate" href="http://apatheia.info/blog/2013/06/17/docker/"/>
    <id>http://apatheia.info/blog/2013/06/17/docker/</id>
    <published>2013-06-17T09:13:00Z</published>
    <updated>2013-06-17T09:13:00Z</updated>
    <author>
      <name>f440</name>
    </author>
    <content type="html">&lt;p&gt;ちょっと前から &lt;a href="http://www.docker.io/"&gt;Docker&lt;/a&gt; を使っているので、その話。&lt;/p&gt;



&lt;h2 id="dockr-"&gt;Dockr について&lt;/h2&gt;

&lt;p&gt;&lt;a href="http://www.docker.io/"&gt;Docker&lt;/a&gt; は &lt;a href="https://www.dotcloud.com/"&gt;dotcloud&lt;/a&gt; がオープンソースで公開している、コンテナ技術による仮想化ソフトウェア。&lt;/p&gt;

&lt;p&gt;以下のテクノロジーベースにしている:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href="http://lxc.sourceforge.net/"&gt;LXC&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;a href="/blog/2012/05/13/vps-lxc-xtradb-cluster/"&gt;前にも書いた&lt;/a&gt;。Xen とか VirtualBOX みたいにホスト内に仮想マシンを立ち上げるんじゃなくて、ホスト内の隔離された環境で仮想マシンを動かす技術。物理マシンをシミュレーションしているんじゃないってことは、VPS とか EC2 とかの仮想マシン上でも問題なく動くし、マシンを起動するプロセスが不要となるので、一瞬で使い始められるというメリットにつながっている。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href="http://aufs.sourceforge.net/"&gt;AUFS&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;UnionFS(ディレクトリを重ね合わせることができる)の実装の一つ。元の仮想マシンイメージを書き換えないで、更新が発生した部分は別の場所に書き込んでいくようになっている。これにより、仮想マシンの立ち上げ時にイメージのコピーが発生しないので、すぐに使い始められる。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Docker を使う前は LXC のラッパーとして取っつきにくさを緩和してくれる、とかそういうレベルだと思ったんだけど、予想はよい方向に裏切られた。&lt;/p&gt;

&lt;p&gt;&lt;a href="http://docs.docker.io/en/latest/commandline/command/images/"&gt;仮想マシンのイメージを可視化したもの&lt;/a&gt;を見ると、まるで Git のコミットログみたいに見えると思う。実際、情報は差分で管理され、履歴を残したり分岐させたりといった操作が非常に軽量にできていて、Git を操作するかのように仮想マシンを操作できるようになっている。&lt;/p&gt;

&lt;h2 id="section"&gt;動かし方&lt;/h2&gt;

&lt;p&gt;Arch Linux や Debian で動かしている人がいるみたいだけど、公式サポートは今のところ Ubuntu のみ。Ubuntu 12.04 LTS を使っているのであれば、&lt;code&gt;curl get.docker.io | sh -x&lt;/code&gt; で動くようになる。&lt;/p&gt;

&lt;p&gt;ちゃんとしたやり方は &lt;a href="http://docs.docker.io/en/latest/installation/"&gt;ドキュメント&lt;/a&gt;を見れば、特にはまることもないと思う。できるだけ新しい Ubuntu を使っておけばいい。&lt;/p&gt;

&lt;p&gt;すぐに試してみたいんなら、Vagrant 経由で簡単に使い始められる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;git clone https://github.com/dotcloud/docker.git
cd docker
vagrant up --provider virtualbox # or vagrant up --provider aws
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id="section-1"&gt;基礎的な操作方法&lt;/h2&gt;

&lt;p&gt;インストールがうまくいって Docker が起動しているものとして、早速使ってみる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker
Usage: docker [OPTIONS] COMMAND [arg...]
  -H="127.0.0.1:4243": Host:port to bind/connect to

  A self-sufficient runtime for linux containers.

  Commands:
  attach    Attach to a running container
  build     Build a container from a Dockerfile
  commit    Create a new image from a container's changes
(以下省略)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;コマンドがずらっと表示されるかと思う。まずは単発のコマンドをコンテナ内で実行してみる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker run base /bin/echo hi
Pulling repository base from https://index.docker.io/v1
Pulling image b750fe79269d2ec9a3c593ef05b4332b1d1a02a62b4accb2c21d589ff2f5f2dc (latest) from base
Pulling b750fe79269d2ec9a3c593ef05b4332b1d1a02a62b4accb2c21d589ff2f5f2dc metadata
Pulling b750fe79269d2ec9a3c593ef05b4332b1d1a02a62b4accb2c21d589ff2f5f2dc fs layer
Downloading 10240/? (n/a)
Pulling 27cf784147099545 metadata
Pulling 27cf784147099545 fs layer
Downloading 94863360/? (n/a)
Pulling image 27cf784147099545 () from base
hi
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;「&lt;code&gt;docker&lt;/code&gt; コマンドに run サブコマンドを指定して、&lt;code&gt;base&lt;/code&gt; という仮想マシンで &lt;code&gt;/bin/echo hi&lt;/code&gt; コマンドを実行する」という意味になる。仮想マシンがダウンロードされるが、これは初回実行時のみ。最後に表示された「hi」というのが今回の実行結果で、このコンテナの役割はこれで終わり。&lt;/p&gt;

&lt;p&gt;今度は作ったマシンの中に入ってみるために、&lt;code&gt;-i&lt;/code&gt; と &lt;code&gt;-t&lt;/code&gt; オプションで入出力できるようにして &lt;code&gt;/bin/bash&lt;/code&gt; を起動してみる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker run -i -t base /bin/bash
root@bc43a290f0ce:/#
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;端末から抜けるとホスト側に制御が戻る。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;root@bc43a290f0ce:/# exit
exit
$
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;今度は &lt;code&gt;-d&lt;/code&gt; オプションでコマンドを実行しっぱなしにする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker run -i -t -d base /bin/ping -i 5 www.aikatsu.net
79365b2985c4
$
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ID が返されて、すぐに端末が利用可能になる。稼働中のプロセスを確認してみる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker ps
ID                  IMAGE               COMMAND                CREATED             STATUS              PORTS
79365b2985c4        base:latest         /bin/ping -i 5 www.a   22 seconds ago      Up 21 seconds
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;次に実行中の出力をのぞいてみよう。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker logs 79365b2985c4
PING www.aikatsu.net (60.32.7.37) 56(84) bytes of data.
64 bytes from www3.sunrise-anime.jp (60.32.7.37): icmp_req=1 ttl=49 time=282 ms
64 bytes from www3.sunrise-anime.jp (60.32.7.37): icmp_req=3 ttl=49 time=278 ms
64 bytes from www3.sunrise-anime.jp (60.32.7.37): icmp_req=4 ttl=49 time=283 ms
64 bytes from www3.sunrise-anime.jp (60.32.7.37): icmp_req=5 ttl=49 time=266 ms
64 bytes from www3.sunrise-anime.jp (60.32.7.37): icmp_req=6 ttl=49 time=268 ms
64 bytes from www3.sunrise-anime.jp (60.32.7.37): icmp_req=8 ttl=49 time=264 ms
64 bytes from www3.sunrise-anime.jp (60.32.7.37): icmp_req=9 ttl=49 time=270 ms
64 bytes from www3.sunrise-anime.jp (60.32.7.37): icmp_req=10 ttl=49 time=290 ms
64 bytes from www3.sunrise-anime.jp (60.32.7.37): icmp_req=11 ttl=49 time=284 ms
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;順調に動き続けているようなので、このジョブにアタッチしてみる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker attach 79365b2985c4
64 bytes from www3.sunrise-anime.jp (60.32.7.37): icmp_req=18 ttl=49 time=239 ms
64 bytes from www3.sunrise-anime.jp (60.32.7.37): icmp_req=19 ttl=49 time=291 ms
64 bytes from www3.sunrise-anime.jp (60.32.7.37): icmp_req=20 ttl=49 time=275 ms
(出力が続く)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;アタッチ中の端末は &lt;code&gt;Ctrl-p Ctrl-q&lt;/code&gt; でデタッチできる。(このとき use of closed network connection っていうエラーが出る場合 Ctrl-c で抜けるしかないっぽい。バグレポートは上がっているので、じきに直ると思う。)&lt;/p&gt;

&lt;p&gt;最後に&lt;code&gt;kill&lt;/code&gt;でこのプロセスを消してみる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker kill 79365b2985c4
$ docker ps
$
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;ps&lt;/code&gt;からプロセスが消えた。基礎的なコンテナの操作の説明は以上。&lt;/p&gt;

&lt;h2 id="section-2"&gt;詳細&lt;/h2&gt;

&lt;h3 id="section-3"&gt;コンテナ&lt;/h3&gt;

&lt;p&gt;これまでコマンドを実行したり、&lt;code&gt;kill&lt;/code&gt; されたコンテナはどうなっているのか。実は全部残っている。停止したコンテナを表示するために&lt;code&gt;-a&lt;/code&gt;をつける。ついでに、情報を省略しないで表示するために&lt;code&gt;-notrunc&lt;/code&gt; もつける。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker ps -a -notrunc
ID                                                                 IMAGE               COMMAND                          CREATED             STATUS              PORTS
79365b2985c43a2a6977764f4dde2d375084020fbc04cc855508c417a36f88c2   base:latest         /bin/ping -i 5 www.aikatsu.net   14 minutes ago      Exit 0
bc43a290f0ced4677ee7eb1a0d662cca496cc720d8db20e746dda45e4659f503   base:latest         /bin/bash                        16 minutes ago      Exit 0
7a666192cca72cea81cade398b22700c982fbb9271a7eca23ff51c6c504d5971   base:latest         /bin/echo hi                     16 minutes ago      Exit 0
8b0af4fc390d762c33dadc1b149516ba95bdb70d093e991ec2df563817f55ffb   base:latest         /bin/bash                        21 minutes ago      Exit 0
4637bc6341706c25e066c5ccfe92e10c923bfe4955a9e8b3ce07237fda0fb34a   base:latest         /bin/echo hi                     21 minutes ago      Exit 0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;正常終了しているので、すべて&lt;code&gt;Exit 0&lt;/code&gt;になっている。また、ID は省略表記されていたこともわかる。コンテナの実体は &lt;code&gt;/var/lib/docker/containers/&amp;lt;ID&amp;gt;&lt;/code&gt; 以下に格納されている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ sudo ls /var/lib/docker/containers/
4637bc6341706c25e066c5ccfe92e10c923bfe4955a9e8b3ce07237fda0fb34a
79365b2985c43a2a6977764f4dde2d375084020fbc04cc855508c417a36f88c2
7a666192cca72cea81cade398b22700c982fbb9271a7eca23ff51c6c504d5971
8b0af4fc390d762c33dadc1b149516ba95bdb70d093e991ec2df563817f55ffb
bc43a290f0ced4677ee7eb1a0d662cca496cc720d8db20e746dda45e4659f503
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;どんどんたまっていくから心配かもしれないけど、各コンテナはベースイメージからの差分しかもたないので、問題にならない。もし、消したくなったら &lt;code&gt;docker rm &amp;lt;コンテナのID&amp;gt;&lt;/code&gt; で消せる。&lt;/p&gt;

&lt;p&gt;作業領域であったコンテナを &lt;code&gt;commit&lt;/code&gt; するとイメージとして使い回せるようになる。&lt;code&gt;ユーザー名/名称&lt;/code&gt;にするのが作法っぽい。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker commit -m "My first container" 4637bc634170 f440/first_container
02036952e5dc
$ docker images
REPOSITORY             TAG                 ID                  CREATED
base                   latest              b750fe79269d        12 weeks ago
base                   ubuntu-quantl       b750fe79269d        12 weeks ago
base                   ubuntu-quantal      b750fe79269d        12 weeks ago
base                   ubuntu-12.10        b750fe79269d        12 weeks ago
f440/first_container   latest              02036952e5dc        3 seconds ago
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これで今後は &lt;code&gt;docker run f440/first_container&lt;/code&gt; をベースにしたコンテナを作れるようになる。&lt;/p&gt;

&lt;h3 id="section-4"&gt;イメージ&lt;/h3&gt;

&lt;p&gt;もう一回イメージの一覧を内容を確認してみよう。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker images
REPOSITORY             TAG                 ID                  CREATED
f440/first-container   latest              141fef9a2f57        14 seconds ago
base                   latest              b750fe79269d        12 weeks ago
base                   ubuntu-12.10        b750fe79269d        12 weeks ago
base                   ubuntu-quantl       b750fe79269d        12 weeks ago
base                   ubuntu-quantal      b750fe79269d        12 weeks ago
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;base イメージは latest, ubuntu-quantl, ubuntu-quantal, ubuntu-12.10 といった複数のタグがついていることがわかる。イメージは複数の名称をタグ付けできるようになっており、&lt;code&gt;base:latest&lt;/code&gt;, &lt;code&gt;base:ubuntu-12.10&lt;/code&gt; といった形で異なるイメージを呼び出せるようになっている。省略時は &lt;code&gt;base:latest&lt;/code&gt; と同じ。&lt;/p&gt;

&lt;p&gt;pull してくるイメージは &lt;a href="https://index.docker.io/"&gt;https://index.docker.io/&lt;/a&gt; から情報を持ってくる。コマンドラインで検索したい場合は &lt;code&gt;search&lt;/code&gt; コマンドを利用する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker search centos
Found 4 results matching your query ("centos")
NAME                          DESCRIPTION
centos
backjlack/centos-6.4-x86_64
creack/centos
mbkan/lamp                    centos with ssh, LAMP, PHPMyAdmin(root pas...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ローカルにキャッシュされたイメージを消すには &lt;code&gt;docker rmi &amp;lt;イメージのID&amp;gt;&lt;/code&gt;でいい。&lt;/p&gt;

&lt;p&gt;自前で作ったイメージを &lt;a href="https://index.docker.io/"&gt;https://index.docker.io/&lt;/a&gt;  に登録するには、あらかじめサイト上でアカウントを作っておき、 &lt;code&gt;docker login&lt;/code&gt; した後に &lt;code&gt;docker push&lt;/code&gt; する。イメージ名にアンダーバー使っていると &lt;code&gt;push&lt;/code&gt; で失敗するのと、アップロードしたイメージを消す機能がまだなかったりするので注意。&lt;/p&gt;

&lt;p&gt;イメージの実体は &lt;code&gt;/var/lib/docker/graph/&lt;/code&gt; にある。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker images -a -notrunc
REPOSITORY          TAG                 ID                                                                 CREATED
base                latest              b750fe79269d2ec9a3c593ef05b4332b1d1a02a62b4accb2c21d589ff2f5f2dc   12 weeks ago
base                ubuntu-12.10        b750fe79269d2ec9a3c593ef05b4332b1d1a02a62b4accb2c21d589ff2f5f2dc   12 weeks ago
base                ubuntu-quantl       b750fe79269d2ec9a3c593ef05b4332b1d1a02a62b4accb2c21d589ff2f5f2dc   12 weeks ago
base                ubuntu-quantal      b750fe79269d2ec9a3c593ef05b4332b1d1a02a62b4accb2c21d589ff2f5f2dc   12 weeks ago
&amp;lt;none&amp;gt;              &amp;lt;none&amp;gt;              27cf784147099545                                                   12 weeks ago

$ sudo ls -1 /var/lib/docker/graph
141fef9a2f57e86dd6d9aa58fe9318b0d9d71d91053079842051d9738bad6e45
27cf784147099545
b750fe79269d2ec9a3c593ef05b4332b1d1a02a62b4accb2c21d589ff2f5f2dc
checksums
:tmp:
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ここで images に ID: 27cf784147099545 というのが現れた。これは何か。&lt;code&gt;inspect&lt;/code&gt; を使うとイメージの詳細を表示できる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker inspect base
{
    "id": "b750fe79269d2ec9a3c593ef05b4332b1d1a02a62b4accb2c21d589ff2f5f2dc",
    "parent": "27cf784147099545",
    "created": "2013-03-23T22:24:18.818426-07:00",
    "container": "3d67245a8d72ecf13f33dffac9f79dcdf70f75acb84d308770391510e0c23ad0",
    "container_config": {
        "Hostname": "",
        "User": "",
        "Memory": 0,
        "MemorySwap": 0,
        "CpuShares": 0,
        "AttachStdin": false,
        "AttachStdout": false,
        "AttachStderr": false,
        "PortSpecs": null,
        "Tty": true,
        "OpenStdin": true,
        "StdinOnce": false,
        "Env": null,
        "Cmd": [
            "/bin/bash"
        ],
        "Dns": null,
        "Image": "base",
        "Volumes": null,
        "VolumesFrom": ""
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ID: 27cf784147099545 は base イメージの親イメージの ID であることがわかる。イメージは差分になっているので、親のイメージが必要ということで初回実行のタイミングで base と一緒に 27cf784147099545 もダウンロードされていたのだった。&lt;/p&gt;

&lt;h3 id="section-5"&gt;ネットワーク&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;docker run&lt;/code&gt; 時に &lt;code&gt;-p&lt;/code&gt; をつけることで、コンテナから外部にさらすポートを決められる。コンテナ側のポートはホスト側のポートに変換される際、ポート番号が変更される(49153以降になる)ので、&lt;code&gt;docker port &amp;lt;ジョブのID&amp;gt; &amp;lt;ポート番号&amp;gt;&lt;/code&gt; あるいは &lt;code&gt;docker ps &lt;/code&gt; でポートの対応状況を確認する必要がある。&lt;/p&gt;

&lt;p&gt;ドキュメントの &lt;a href="https://github.com/dotcloud/docker#expose-a-service-on-a-tcp-port"&gt;Expose a service on a TCP port&lt;/a&gt; がわかりやすい。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# 以下、コメントは書き換えてある
# また、途中経過がわかりやすいように set -x しておく
set -x

# 4444 を晒すよう -p オプションをつけて docker run しつつ、
# コンテナは netcat で4444を待ち受ける
JOB=$(docker run -d -p 4444 base /bin/nc -l -p 4444)
++ docker run -d -p 4444 base /bin/nc -l -p 4444
+ JOB=c86c892574f7

# 4444 がローカルのどのポートに対応するのか確認
# docker ps でも調べることはできる
PORT=$(docker port $JOB 4444)
++ docker port c86c892574f7 4444
+ PORT=49166

# ルーティングによっては localhost とか 127.0.0.1 だと
# うまくいかないことがあるので、eth0 のIPアドレスを使おう、
# ってことらしい
IP=$(ifconfig eth0 | perl -n -e 'if (m/inet addr:([\d\.]+)/g) { print $1 }')
++ perl -n -e 'if (m/inet addr:([\d\.]+)/g) { print $1 }'
++ ifconfig eth0
+ IP=10.156.137.111
echo hello world | nc $IP $PORT
+ nc 10.156.137.111 49166
+ echo hello world

# コンテナが受信したメッセージを logs で表示
echo "Daemon received: $(docker logs $JOB)"
++ docker logs c86c892574f7
+ echo 'Daemon received: hello world'
Daemon received: hello world
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id="dockerfile"&gt;Dockerfile&lt;/h3&gt;

&lt;p&gt;DSLで書かれた設定(通常ファイル名は&lt;code&gt;Dockerfile&lt;/code&gt;とする)をあらかじめ用意することで、手順に従ってイメージを作ることができる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;読み込ませ方 (1)
docker build &amp;lt;Dockerfileのあるディレクトリ&amp;gt;
# ex. docker build .

読み込ませ方 (2)
docker build -
# ex. docker build - &amp;lt; /foo/bar/Dockerfile
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Dockerfile の例&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;FROM base
RUN /bin/echo hi
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これで、&lt;code&gt;docker build&lt;/code&gt; すれば &lt;code&gt;docker run base /bin/echo hi&lt;/code&gt; と同じ効果が得られる。&lt;/p&gt;

&lt;p&gt;指定できるはコマンドは以下の通り。大文字小文字は区別しないけど、引数と見分けやすいように大文字が使われる。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code&gt;FROM &amp;lt;image&amp;gt;&lt;/code&gt; ベースとなるイメージを指定&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;MAINTAINER &amp;lt;name&amp;gt;&lt;/code&gt; メンテナの名前を指定&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;RUN &amp;lt;command&amp;gt;&lt;/code&gt; ビルド中に実行したいコマンドを指定&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;CMD &amp;lt;command&amp;gt;&lt;/code&gt; 起動後のコンテナで実行したいコマンドを指定&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;EXPOSE &amp;lt;port&amp;gt; [&amp;lt;port&amp;gt; ...]&lt;/code&gt; 外部に晒すポートの指定&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;ENV &amp;lt;key&amp;gt; &amp;lt;value&amp;gt;&lt;/code&gt; 環境変数の設定&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;INSERT &amp;lt;file url&amp;gt; &amp;lt;path&amp;gt;&lt;/code&gt; deprecated なので ADD を利用すること&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;ADD &amp;lt;src&amp;gt; &amp;lt;dest&amp;gt;&lt;/code&gt; ファイルを配置&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code&gt;RUN&lt;/code&gt; と &lt;code&gt;CMD&lt;/code&gt; の違いがわかりにくいかもしれない。例を出す。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# RUN, CMD で指定したコマンドが実行されたとき、
# 標準出力と /tmp/*.log に記録を残す

$ cat &amp;lt;&amp;lt;SCRIPT &amp;gt;Dockerfile
&amp;gt; FROM base
&amp;gt; RUN /bin/echo run | tee /tmp/run.log
&amp;gt; CMD /bin/echo cmd | tee /tmp/cmd.log
&amp;gt; SCRIPT

# ビルドの実行

$ docker build .
Caching Context 10240/? (n/a)
FROM base ()
===&amp;gt; b750fe79269d2ec9a3c593ef05b4332b1d1a02a62b4accb2c21d589ff2f5f2dc
RUN /bin/echo run | tee /tmp/run.log (b750fe79269d2ec9a3c593ef05b4332b1d1a02a62b4accb2c21d589ff2f5f2dc)
===&amp;gt; d10b6bd1321d45b0228b5741c01d1f76fd0288052e56836609f9bdf217854f3d
CMD /bin/echo cmd | tee /tmp/cmd.log (d10b6bd1321d45b0228b5741c01d1f76fd0288052e56836609f9bdf217854f3d)
===&amp;gt; 60671e9969185841032fb02f623917672c4f871a6be68e5aa575e8fdf1f94229
Build successful.
===&amp;gt; 60671e9969185841032fb02f623917672c4f871a6be68e5aa575e8fdf1f94229

# run, cmd の実行結果を確認
# =&amp;gt; run だけが実行されている

$ docker run 60671e99691 /bin/ls /tmp/
run.log

# イメージを inspect する
# =&amp;gt; どうやらコンテナは記憶していることがわかる

$ docker inspect 60671e99691
{
    "id": "60671e9969185841032fb02f623917672c4f871a6be68e5aa575e8fdf1f94229",
    "parent": "d10b6bd1321d45b0228b5741c01d1f76fd0288052e56836609f9bdf217854f3d",
    "created": "2013-06-16T16:29:14.602237Z",
    "container": "4c54683cec90500f329dfaad2e0856cc408483be0ae3166018121d4d4b9b3282",
    "container_config": {
        "Hostname": "78c72f8ba6ad",
        "User": "",
        "Memory": 0,
        "MemorySwap": 0,
        "CpuShares": 0,
        "AttachStdin": false,
        "AttachStdout": false,
        "AttachStderr": false,
        "PortSpecs": null,
        "Tty": false,
        "OpenStdin": false,
        "StdinOnce": false,
        "Env": null,
        "Cmd": [
            "/bin/sh",
            "-c",
            "#(nop) CMD [/bin/sh -c /bin/echo cmd | tee /tmp/cmd.log]"
        ],
        "Dns": null,
        "Image": "d10b6bd1321d45b0228b5741c01d1f76fd0288052e56836609f9bdf217854f3d",
        "Volumes": null,

# 引数でコマンドを指定せずに run を実行
# =&amp;gt; cmd で登録した内容が実行される

$ docker run 60671e99691
cmd
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;つまり、&lt;code&gt;RUN&lt;/code&gt; は &lt;code&gt;Dockerfile&lt;/code&gt; を元にビルドしているときに参照され、&lt;code&gt;CMD&lt;/code&gt; はコンテナを実行する際に参照されるということがわかる。パッケージをインストールしたりといった用途では通常 &lt;code&gt;RUN&lt;/code&gt; を使う。&lt;/p&gt;

&lt;h2 id="section-6"&gt;まとめ&lt;/h2&gt;

&lt;p&gt;仮想環境の発達でプログラマブルなインフラストラクチャーは実現できてきているけど、マシンを上げたり下げたりするのにどうしても時間がかかるし、それは仕方が無いものと我慢していた。&lt;code&gt;Docker&lt;/code&gt; を使ってみると、今までのそういった不満から解放されることができそう。一応開発中というステータスなのでプロダクション環境では使いづらいけど、開発やテスト、とくに構成管理ツールを設定するときなどは、この俊敏性、柔軟性は有効になると思う。&lt;/p&gt;

&lt;h2 id="section-7"&gt;参考&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href="http://docs.docker.io/en/latest/"&gt;Documentation&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

</content>
  </entry>
  <entry>
    <title>yum のパッケージキャッシュについて</title>
    <link rel="alternate" href="http://apatheia.info/blog/2013/06/16/yum-cache/"/>
    <id>http://apatheia.info/blog/2013/06/16/yum-cache/</id>
    <published>2013-06-16T01:26:00Z</published>
    <updated>2013-06-16T01:26:00Z</updated>
    <author>
      <name>f440</name>
    </author>
    <content type="html">&lt;p&gt;&lt;code&gt;/etc/yum.conf&lt;/code&gt;で&lt;code&gt;keepcache=1&lt;/code&gt;にしておくと、インストールしたパッケージがキャッシュされるようになる。これが無効化された状態だと、パッケージアップグレード時に問題が起きても元に戻せなくなるので有効化しておいた方がいい。&lt;/p&gt;



&lt;p&gt;あるパッケージについて、どのバージョンが利用可能な状態かは以下で確認できる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ sudo yum --showduplicates list パッケージ名
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;RHEL なら過去のバージョンまですべて手に入るけど、CentOS だとOSリリース時のバージョンと最新版しか手に入らない模様。リポジトリ上なりキャッシュなりで過去のバージョンが手に入るのであれば、&lt;code&gt;yum install&lt;/code&gt; や &lt;code&gt;yum update&lt;/code&gt; は以下の手順でロールバックが行える。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# yum の利用履歴を確認
$ sudo yum history

# 履歴から詳細を確認
# 未引数なら直近、引数ありなら該当する ID を表示
$ sudo yum history info 4

# 仮に ID 4 で問題のバージョンアップが行われたようだということが確認できたら、その ID を指定して操作をアンドゥ
$ sudo yum history undo 4
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;アンドゥ(リドゥもある)では、対象パッケージおよび依存パッケージがまとめて一度に入れ替えられる。これはパッケージの操作がちゃんとトランザクションになっているため。&lt;/p&gt;

&lt;p&gt;話がそれるけど、パッケージの操作にトランザクションがかかるというのはかなり重要だ。たとえば syslog-ng から rsyslog に入れ替えるとき、単純にアンインストール、インストールの順番でやろうとするとアンインストールのタイミングで大量の Syslog 依存なパッケージが道連れになるけど、以下のようにすればひとつのトランザクションでパッケージを入れ替えることができる。(情報源: &lt;a href="http://wiki.rsyslog.com/index.php/Install_rsyslog_with_yum"&gt;Rsyslog Wiki&lt;/a&gt;)&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ sudo yum shell
&amp;gt; remove syslog-ng
&amp;gt; install rsyslog
&amp;gt; run
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;話がそれたついでにふれておくと、vagrant を使っているのであれば &lt;a href="https://github.com/fgrehm/vagrant-cachier"&gt;vagrant-cachier&lt;/a&gt; を使うとパッケージのキャッシュ保存先を仮想マシン外の領域(ホストOSとの共有ディスク部分など)に変更してくれる。こうすることで、仮想マシンを破棄してもパッケージのキャッシュが永続化されるため、2回目以降はダウンロードがスキップされて高速化する。&lt;/p&gt;

&lt;p&gt;話を戻すと、世の中何が起きるかわからないので古いパッケージもとっておいたほうがいいかと。ディスク容量が気になりだしたら、&lt;code&gt;yum clean packages&lt;/code&gt; を実行すればキャッシュは消せる。&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>omnibus を使って オムニバスインストーラーを作成する</title>
    <link rel="alternate" href="http://apatheia.info/blog/2013/05/07/create-ominibus-installer/"/>
    <id>http://apatheia.info/blog/2013/05/07/create-ominibus-installer/</id>
    <published>2013-05-07T01:41:00Z</published>
    <updated>2013-05-07T01:41:00Z</updated>
    <author>
      <name>f440</name>
    </author>
    <content type="html">&lt;p&gt;Chef のインストールは結構面倒くさかったんだけど、&lt;a href="http://www.opscode.com/chef/install/"&gt;オムニバスインストーラー&lt;/a&gt;が出たことで状況はがらっと変わって、簡単に導入できるようになった。このオムニバスインストーラーの仕組みは汎用的に作られているので、他のツールでも適用できるという話。&lt;/p&gt;



&lt;h2 id="section"&gt;オムニバスインストーラーについて&lt;/h2&gt;

&lt;p&gt;Chef のオムニバスインストーラーを実行すると以下のようなディレクトリ構成でファイルが置かれる:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;/opt/chef/bin/ … Chef 関連のスクリプト&lt;/li&gt;
  &lt;li&gt;/opt/chef/embedded/ … ruby インタプリタ、Chef とその他依存パッケージ&lt;/li&gt;
  &lt;li&gt;(/usr/bin/ … /opt/chef/bin/ 以下のものがシンボリックリンクが配置される)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;以上の通り、&lt;code&gt;/opt/chef&lt;/code&gt; の中に動作に必要なものがごっそり置かれる。アプリケーションレベルでプログラミングの処理系を持っちゃうというのはこれに限らずよく見る光景で、理由としてはパッケージ提供されていない最新版が使いたかったり、バージョンアップやライブラリインストールの影響範囲を限定させたかったりだと思う。&lt;/p&gt;

&lt;p&gt;ここしばらくは手軽なパッケージ作成ツールとして&lt;a href="https://github.com/jordansissel/fpm"&gt;fpm&lt;/a&gt;がよく使われているけど、オムニバスインストーラーは&lt;a href="https://github.com/opscode/omnibus-ruby"&gt;omnibus&lt;/a&gt;という「ビルドツール」＋「fpm ラッパー」といった感じのもので作られている。以下は実際に &lt;a href="https://github.com/opscode/omnibus-ruby"&gt;omnibus&lt;/a&gt; を使ったインストーラー作成の手順についてまとめる。&lt;/p&gt;

&lt;h2 id="section-1"&gt;パッケージ作成&lt;/h2&gt;

&lt;p&gt;&lt;a href="https://github.com/etsy/statsd"&gt;statsd&lt;/a&gt; および &lt;a href="https://github.com/etsy/statsd"&gt;statsd&lt;/a&gt; を動かすために必要な Node.js を /opt/statsd にインストールする RPM, Deb パッケージの作成を行ってみる。&lt;/p&gt;

&lt;h3 id="section-2"&gt;環境&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Macbook Air Mountain Lion&lt;/li&gt;
  &lt;li&gt;Ruby 2.0.0-p0&lt;/li&gt;
  &lt;li&gt;Vagrant 1.2.2&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id="section-3"&gt;手順&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;# omnibus のインストール
gem install omnibus

# 必要となる vagrant 用の plugin をインストール
vagrant plugin install vagrant-omnibus
vagrant plugin install vagrant-berkshelf

# プロジェクトディレクトリの作成(ディレクトリ名は `omnibus-プロジェクト` となる)
omnibus project statsd
cd omnibus-statsd

# プロジェクトディレクトリ内のファイルを適宜修正:
    Berksfile
      Berkshelf 用の設定。変更する必要無い。
    Vagrantfile
      Vagrant 用の設定。2013-06-07 現在だと CentOS 5, 6 Ubuntu 10.04, 11.04, 12.04 の設定が導入済み。
    README.md
    omnibus.rb.example
      成果物を S3 上にキャッシュする場合などに利用。使わないなら気にしなくていい。
    config/projects/statsd.rb
      後述
    config/software/*
      後述
    package-scripts/statsd/*
      インストール時、アンインストール時などに実行したいスクリプトなど。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;この中で、実際のビルドプロセスを定義するのは、config/projects/ 以下と config/software 以下になる。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;config/projects/&lt;/code&gt; はプロジェクトの設定を格納するディレクトリで、初期状態では statsd 用のプロジェクトファイル &lt;code&gt;config/projects/statsd.rb&lt;/code&gt; が作られている。このファイルを修正していくことになる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;name "statsd"
maintainer "f440"
homepage "https://github.com/f440/omnibus-statsd"

install_path    "/opt/statsd"
build_version   "0.6.0"
build_iteration 1

dependency "preparation"
dependency "node"
dependency "statsd"

exclude "\.git*"
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;おおむね想像がつく名前だけど、dependency だけはよく分からないと思う。dependency で指定したものはプロジェクトを構成する software という扱いで、&lt;code&gt;config/software/&lt;/code&gt; 以下でその設定を行っていく。&lt;/p&gt;

&lt;p&gt;software の例を示す。典型的な例だと、指定した URL からダウンロードしてきたものを一時ディレクトリで展開して、&lt;code&gt;configure &amp;amp;&amp;amp; make &amp;amp;&amp;amp; make install&lt;/code&gt; を実行、などだが今回の作業では Node.js のバイナリを展開して &lt;code&gt;/opt/embedded&lt;/code&gt; 以下にコピーしているだけである。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;name "node"
version "0.10.5"

source :url =&amp;gt; "http://nodejs.org/dist/v0.10.5/node-v0.10.5-linux-x64.tar.gz",
       :md5 =&amp;gt; "fb65723d395c559393201dd41e0eb275"

relative_path "node-v0.10.5-linux-x64"

build do
  command "rsync -av . #{install_dir}/embedded/"
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;必要となる software の設定を全部そろえたらビルドを実行する。マシンの起動、Chef のインストール、omnibus の Cookbook 実行、ビルド環境構築、ビルド実行、パッケージ作成 といったことが行われることになるため、初回はかなり待つことになる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;vagrant up
(vagrant up centos-6 など、直接マシンを指定してもいい)
(もし Linux 上で作業しているのであれば、omnibus build project statsd で直接パッケージ作成を開始出来る)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;問題なければ、pkg/ 以下に statsd-0.6.0-1.el6.x86&lt;em&gt;64.rpm, statsd&lt;/em&gt;0.6.0-1.ubuntu.12.04_amd64.deb といったファイルが出来る。&lt;/p&gt;

&lt;h2 id="section-4"&gt;まとめ&lt;/h2&gt;

&lt;p&gt;やっていることは &lt;a href="https://github.com/jordansissel/fpm"&gt;fpm&lt;/a&gt; でパッケージを作っているだけなんだけど、&lt;a href="http://www.vagrantup.com/"&gt;Vagrant&lt;/a&gt; x &lt;a href="http://berkshelf.com/"&gt;Berkshelf&lt;/a&gt; x &lt;a href="http://www.opscode.com/chef/"&gt;Chef&lt;/a&gt; のコンビネーションのおかげで、パッケージとそのパッケージを作るための環境が簡単に手に入るのはとてもいい。複数環境のパッケージを作る予定がなくっても、最初から&lt;a href="https://github.com/opscode/omnibus-ruby"&gt;omnibus&lt;/a&gt;上でパッケージを作れるようにしておくと運用が楽そう。&lt;/p&gt;

&lt;h2 id="section-5"&gt;備考&lt;/h2&gt;

&lt;p&gt;似たようなツールとして、&lt;a href="https://github.com/joemiller/bunchr"&gt;bunchr&lt;/a&gt; が存在する。&lt;/p&gt;

&lt;h2 id="section-6"&gt;参考&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href="https://github.com/etsy/statsd"&gt;Statsd&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="http://www.opscode.com/chef/install/"&gt;Install Chef&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://github.com/opscode/omnibus-ruby"&gt;omnibus&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://github.com/joemiller/bunchr"&gt;bunchr&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://github.com/jordansissel/fpm"&gt;fpm&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="http://www.vagrantup.com/"&gt;Vagrant&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="http://berkshelf.com/"&gt;Berkshelf&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

</content>
  </entry>
  <entry>
    <title>fpm で Mesos の RPM を作るまで</title>
    <link rel="alternate" href="http://apatheia.info/blog/2013/05/03/create-mesos-rpm-using-fpm/"/>
    <id>http://apatheia.info/blog/2013/05/03/create-mesos-rpm-using-fpm/</id>
    <published>2013-05-03T17:24:00Z</published>
    <updated>2013-05-03T17:24:00Z</updated>
    <author>
      <name>f440</name>
    </author>
    <content type="html">&lt;p&gt;&lt;a href="http://incubator.apache.org/mesos/"&gt;Mesos&lt;/a&gt; をインストールするとき各マシンでビルドはしんどいので、&lt;a href="https://github.com/jordansissel/fpm"&gt;fpm&lt;/a&gt; で Mesos の RPM を作ってインストールしている。ビルドからパッケージ作成までの作業ログを残しておく。&lt;/p&gt;



&lt;ul&gt;
  &lt;li&gt;&lt;a href="https://github.com/jordansissel/fpm"&gt;fpm&lt;/a&gt; は Ruby の gem や Node.js の npm などのプログラミング言語のライブラリ、あるいは直接ディレクトリから RPM やら Deb やらのパッケージを作成するソフトウェア。&lt;/li&gt;
  &lt;li&gt;&lt;a href="http://incubator.apache.org/mesos/"&gt;Mesos&lt;/a&gt; はクラスタ構成のリソースをよしなに管理するソフトウェア。
    &lt;ul&gt;
      &lt;li&gt;今回の話では具体的な使い方までは触れない&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id="section"&gt;手順&lt;/h2&gt;

&lt;p&gt;作業環境は CentOS 6.4 x86_64。&lt;/p&gt;

&lt;p&gt;Ruby をインストール。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo yum install ruby.x86_64 rubygems ruby-devel.x86_64 rpm-build.x86_64
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;fpm をインストール。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo gem install fpm --no-rdoc --no-ri
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Mesos のソースをダウンロード、展開。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;curl -LO http://ftp.meisei-u.ac.jp/mirror/apache/dist/incubator/mesos/mesos-0.10.0-incubating/mesos-0.10.0-incubating.tar.gz
tar xf mesos-0.10.0-incubating.tar.gz
cd mesos-0.10.0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Mesos のビルドに必要なパッケージをインストール。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo yum install gcc-c++.x86_64 patch.x86_64 python-devel.x86_64 \
  cppunit-devel.x86_64 java-1.6.0-openjdk-devel.x86_64
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ビルド。今回は、configure のオプションで Redhat っぽい配置を指定している。&lt;code&gt;/opt/mesos&lt;/code&gt; とか &lt;code&gt;/usr/local/mesos&lt;/code&gt; に全部まとめたければ –prefix を使うなど、このあたりはお好みで。
&lt;code&gt;make install&lt;/code&gt; 時には書き込み可能な場所を DESTDIR で指定。説明中では、&lt;code&gt;/tmp/mesos&lt;/code&gt; を利用している。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;JAVA_HOME=/etc/alternatives/java_sdk ./configure \
  --bindir=/usr/bin --sbindir=/usr/sbin --libexecdir=/usr/libexec \
  --localstatedir=/var --libdir=/usr/lib64 --includedir=/usr/include \
  --datarootdir=/usr/share
make
make install DESTDIR=/tmp/mesos
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;fpm でパッケージを作成。詳細は fpm –help を参照。注意点としては、&lt;code&gt;--description&lt;/code&gt; は RPM のメタ情報 &lt;code&gt;description&lt;/code&gt;, &lt;code&gt;summary&lt;/code&gt; で兼用されるので、あまり長い情報を入れると &lt;code&gt;yum search&lt;/code&gt; とかがごちゃごちゃすることになる。適度に切り詰めた方がいい。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;fpm -s dir -t rpm \
  -v 0.10.0 \
  -n mesos \
  -C /tmp/mesos \
  -a x86_64 \
  --license "ASL 2.0" \
  --url "http://incubator.apache.org/mesos/" \
  --description "Dynamic resource sharing for clusters" \
  -d python-devel \
  -d java-1.6.0-openjdk-devel \
  .
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;RPM ファイルのメタ情報やファイル一覧をチェック。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;rpm -qpi mesos-0.10.0-1.x86_64.rpm
rpm -qpl mesos-0.10.0-1.x86_64.rpm
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;あとは、できあがった RPM ファイルを他のマシンに持っていってインストール。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo yum install ./mesos-0.10.0-1.x86_64.rpm
&lt;/code&gt;&lt;/pre&gt;

</content>
  </entry>
  <entry>
    <title>構成管理ツール Ansible について</title>
    <link rel="alternate" href="http://apatheia.info/blog/2013/04/06/about-ansible/"/>
    <id>http://apatheia.info/blog/2013/04/06/about-ansible/</id>
    <published>2013-04-06T14:50:00Z</published>
    <updated>2013-04-06T14:50:00Z</updated>
    <author>
      <name>f440</name>
    </author>
    <content type="html">&lt;p&gt;&lt;a href="http://ansible.cc/"&gt;Ansible&lt;/a&gt; というサーバーの設定を管理するツールの説明。いわゆる構成管理 (CM: Configuration Management) にカテゴライズされるもので、Puppet や Chef の親戚みたいなものと考えてもらえればだいたいあってる。&lt;/p&gt;



&lt;h2 id="section"&gt;概要&lt;/h2&gt;

&lt;p&gt;リード開発者は Michael DeHaan で、現職の AnsibleWorks の前は Redhat で &lt;a href="http://cobbler.github.io/"&gt;Cobbler&lt;/a&gt; や &lt;a href="https://fedorahosted.org/func/"&gt;Func&lt;/a&gt; に携わっていたり、Puppet labs でプロダクトマネージャーしたりしているという経歴の持ち主。&lt;/p&gt;

&lt;p&gt;Ansible は Python で書かれている。同じジャンルで Python 製というと &lt;a href="http://saltstack.com/"&gt;Salt&lt;/a&gt; が有名。Chef の場合、レシピを書くためには Ruby の知識が必要となってくるけど、Ansible はどんな言語でもモジュールが書けるようになっているので、運用にあたって Python の知識は必要無い。&lt;/p&gt;

&lt;p&gt;動作の点でも Puppet や Chef などのツールとまったく異なるアプローチをしている。Puppet や Chef は、サーバーとクライアントで構成され、クライアントとなるマシンはサーバーに設定を問い合わせながら、自分自身を「あるべき状態」に収束するよう変更を加えていく。Ansible の場合、サーバー側からクライアントとなるサーバー(群)に対して直接命令を送り込み結果を得る。これは &lt;a href="https://fedorahosted.org/func/"&gt;Func&lt;/a&gt;、&lt;a href="http://capistranorb.com/"&gt;Capistrano&lt;/a&gt;、&lt;a href="http://fabfile.org/"&gt;Fabric&lt;/a&gt; などに似ているが、これらのデプロイを目的としたツールにはない「何回やっても結果が同じ」(idempotence) という CM ツールらしさはちゃんと備えている。&lt;/p&gt;

&lt;p&gt;ドキュメントは12ページしかなく(ちなみに、さっき数えてみたらChefのドキュメントは2834ファイルあった) 非常に習得は簡単。サーバーを立てる必要もなく、クライアントマシンもエージェントレス、加えて短期間で学習できるので手軽感は非常に高いが、モジュール機構が強力なのできわめて実用的になっている。&lt;/p&gt;

&lt;h2 id="section-1"&gt;基本的な概念&lt;/h2&gt;

&lt;p&gt;Ansible を理解する上で重要となる、モジュールとプレーブックについて説明する。&lt;/p&gt;

&lt;h3 id="section-2"&gt;モジュール&lt;/h3&gt;

&lt;p&gt;クライアント内での動きはモジュールという形で定義する。&lt;/p&gt;

&lt;p&gt;パッケージのインストール、サービスの起動、ユーザーやグループの作成などの基本的なモジュールはあるが、実際には環境に合わせて不足分は自分でモジュールを作っていくことになる。&lt;/p&gt;

&lt;p&gt;モジュールは簡単に作れる。モジュールが役割を端的に言うと、以下を行うだけである。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;標準入力でオプションを受け取る&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;標準出力で実行結果を返す&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;出力形式は key=value を空白でつなげたものか JSON&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;これができる言語であれば、シェルスクリプトでも Perl でも問題ない。&lt;/p&gt;

&lt;h3 id="section-3"&gt;プレーブック&lt;/h3&gt;

&lt;p&gt;実際の処理では単発のモジュールでサーバーの設定が終わることはないので、モジュールの使い方をまとめたものが必要になる。Ansible では、YAML で処理をまとめたものを プレーブック (Playbook)と呼んでいる。&lt;/p&gt;

&lt;p&gt;例: Apache と PHP をインストールする (webapp.yml)&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;- hosts: webserver
  user: vagrant
  sudo: yes
  tasks:
    - name: install apache
      action: yum pkg=httpd state=installed
    - name: install php
      action: yum pkg=php state=installed
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;例: 実行&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# ansible-playbook プレーブック名
$ ansible-playbook webapp.yml
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;以上は簡単な例だが、設定ファイルを配置したり、それに併せてサービスを再起動させたりといったことも記述可能。&lt;/p&gt;

&lt;p&gt;プレーブックには以下のような内容が含まれる:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;hosts: 対象のホスト&lt;/li&gt;
  &lt;li&gt;user: 実行ユーザー&lt;/li&gt;
  &lt;li&gt;vars: 変数&lt;/li&gt;
  &lt;li&gt;tasks: タスク&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code&gt;vars&lt;/code&gt; の変数は、テンプレート内で展開される。設定ファイル配置時にパラメータを変更、といった場合に利用する。&lt;/p&gt;

&lt;h3 id="section-4"&gt;インストール&lt;/h3&gt;

&lt;p&gt;以下では、インストールから簡単なコマンドの実行までの例を挙げる。サーバー、クライアント双方で CentOS 6.4 を利用した。&lt;/p&gt;

&lt;p&gt;Ansible を動かすためには、Python 2.6 以上と Ansible のソースコードとごくわずかな Python パッケージだけあればよい。CentOS 6 であれば Python の条件は満たせているし、EPEL で Ansible のパッケージが提供されているので、&lt;code&gt;yum&lt;/code&gt; でインストール可能。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# EPEL 有効化
$ sudo rpm -ivh http://ftp.riken.jp/Linux/fedora/epel/6/i386/epel-release-6-8.noarch.rpm

# Ansible インストール
$ sudo yum install ansible
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;他の Unix 系OSであれば、&lt;code&gt;pip install ansible&lt;/code&gt; でいい。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ sudo pip install ansible
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;次に、サーバーからクライアントに SSH でログインできるように調整しておく。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# 以下のマシンを用意した。
# それぞれホスト名でアクセスできる
#    Ansible 実行側 ... server
#    変更対象 ... client1, client2

# server側で公開鍵認証用の鍵を作成
$ $ ssh-keygen -t rsa

# client に公開鍵を配置する
$ ssh-copy-id client1
$ ssh-copy-id client2

# 試しにログインしてみる
# 頻繁に実行することになるので、公開鍵にパスフレーズを
# 設定している場合は、ssh-agent を使ってパスフレーズの
# 入力を省略できるようにしておく。
$ ssh client1
$ ssh client2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;今度は、対象のサーバーを設定してみよう。環境変数 &lt;code&gt;ANSIBLE_HOSTS&lt;/code&gt; にあるファイルでサーバーの指定が可能。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat &amp;lt;EOD &amp;gt;~/target
&amp;gt; [webserver]
&amp;gt; client1
&amp;gt; 
&amp;gt; [dbserver]
&amp;gt; client2
&amp;gt; EOD
$ export ANSIBLE_HOSTS=~/target
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;設定の中で、&lt;code&gt;[ ]&lt;/code&gt; によりグループを作っている。つまり「webserver グループに client1、dbserver グループに client2 が所属している」ということを表している。グループはオプションなので、単純にホスト名を羅列するだけでもいい。試しに、対象のホストを調べてみよう。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# ansible ホストパターン --list-hosts

# ホスト名を直接指定
$ ansible client1 --list-hosts
client1

# グループ名を指定
$ ansible webserver --list-hosts
client1
$ ansible dbserver --list-hosts
client2

# all を指定した場合、全サーバーを列挙
$ ansible all --list-hosts
client1
client2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これだけで準備は完了。実行してみる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# コマンドの書式
ansible 対象 -m モジュール名 -a オプション

# 例 ping モジュール
$ ansible all -m ping
client2 | success &amp;gt;&amp;gt; {
    "changed": false,
    "ping": "pong"
}

client1 | success &amp;gt;&amp;gt; {
    "changed": false,
    "ping": "pong"
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;-m&lt;/code&gt; をつけないで、直接コマンドを実行することも可能。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# すべてのマシンでカーネルのバージョンを取得
$ ansible all -a 'uname -r'
client2 | success | rc=0 &amp;gt;&amp;gt;
2.6.32-358.el6.x86_64

client1 | success | rc=0 &amp;gt;&amp;gt;
2.6.32-358.el6.x86_64
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;プレーブックを実行したときは以下のようになる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# 対象は webserver というグループ(client1 が所属)に対して、
# Apache と PHP をインストールするプレーブック、webapp.yml を実行
# Apache はすでにインストールされていたので、
# PHP のみインストールされることとなった

$ ansible-playbook webapp.yml

PLAY [webserver] *********************

GATHERING FACTS *********************
ok: [client1]

TASK: [install apache] *********************
ok: [client1]

TASK: [install php] *********************
changed: [client1]

PLAY RECAP *********************
client1                        : ok=3    changed=1    unreachable=0    failed=0
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id="section-5"&gt;その他&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href="https://twitter.com/mitchellh/status/319914935910027264"&gt;Vagrant もバージョン 1.2 から Ansible でのプロビジョニングをサポート予定&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;開発は活発&lt;/li&gt;
  &lt;li&gt;リリース名がヴァンヘイレンの曲名 (1.0 は Eruptionだった)&lt;/li&gt;
  &lt;li&gt;ロゴがださい (ML でも 90年代のデザインなんて言われている)&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id="section-6"&gt;まとめ&lt;/h2&gt;

&lt;p&gt;ロゴのセンスは悪いけど、アプリケーション自体の仕組みはすごくセンスがいい。&lt;/p&gt;

&lt;p&gt;他の構成管理ツールと比べると、DSL を覚えるといった「ツールを使うまでののコスト」、ツールのためのサーバー構築・運用といった「ツールを使ってからのコスト」が軽微なので、よりやりたいことに目が向けられるのもうれしい。&lt;/p&gt;

&lt;p&gt;最近日本国内でも Chef の話題を聞くことが多いんだけど、Chef Server の運用とかオートスケールとのコンビネーションとかの情報はあまり聞かないので、たぶん割と小規模な環境でリモートサーバーの Chef-solo をキックみたいなケースが多いのかと思う。そういったところだと、Ansible のほうがふさわしいっていうことが多いんじゃないかな。&lt;/p&gt;

</content>
  </entry>
  <entry>
    <title>イベント管理にSplunk Stormを使ってみる</title>
    <link rel="alternate" href="http://apatheia.info/blog/2013/03/17/logging-with-splunk-storm/"/>
    <id>http://apatheia.info/blog/2013/03/17/logging-with-splunk-storm/</id>
    <published>2013-03-17T21:17:00Z</published>
    <updated>2013-03-17T21:17:00Z</updated>
    <author>
      <name>f440</name>
    </author>
    <content type="html">&lt;p&gt;&lt;a href="http://www.splunk.com/"&gt;Splunk&lt;/a&gt; はおそらくイベント・ログ管理のツールとしてはおそらくもっとも有名で、日本でも販売展開しているので知っている人も多いかと思う。その splunk が &lt;a href="https://www.splunkstorm.com/storm/"&gt;Splunk Storm&lt;/a&gt; というサービスを始めている。試しに使ってみたのでその感想。&lt;/p&gt;



&lt;p&gt;料金に応じて、格納可能なデータの容量が増える課金体系。無料でも1GBまで利用可能。&lt;/p&gt;

&lt;p&gt;データの取り込みは以下の方法が提供されている:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Syslog, Rsyslog, Syslog-ng などから転送&lt;/li&gt;
  &lt;li&gt;TCP/UDP を使って直接登録
    &lt;ul&gt;
      &lt;li&gt;&lt;code&gt;cat some_file.log | nc endpoind_hostname port&lt;/code&gt; で登録可能&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;HTTP API&lt;/li&gt;
  &lt;li&gt;forwarder と呼ばれるクライアントプログラム
    &lt;ul&gt;
      &lt;li&gt;ログの読み取りなども可能&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;ファイルアップロード&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;試しにアカウントをとってApacheのログ形式のデータをncでがんがん取り込んでみたところ、1GB を超えたところでもうこれ以上追加できないとのメールが届いた。結果、200万件以上のデータが登録できていた。&lt;/p&gt;

&lt;p&gt;複雑な検索式を使って特定の条件に合うレコードを弾き出したり、図示することができる。たとえば、ステータスコードでグルーピングしたグラフを表示するには、以下の検索式を指定する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sourcetype="access_combined" status="*" | timechart count by status
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;リアルタイムで計算しているらしく、新しい時間帯から古い時間帯へとどんどんグラフが追加されていく。&lt;/p&gt;

&lt;p&gt;&lt;img src="/images/2013-03-17-logging-with-splunk-storm/httpstatus.png" alt="httpstatus" /&gt;&lt;/p&gt;

&lt;p&gt;さすがというか、よくできている。&lt;/p&gt;

</content>
  </entry>
</feed>
