<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>apatheia.info</title>
  <link href="http://apatheia.info/"/>
  <link href="http://apatheia.info/atom.xml" rel="self"/>
  <updated>2016-02-22T20:54:00+09:00</updated>
  <id>http://apatheia.info/</id>
  <author>
    <name>f440</name>
  </author>
  <entry>
    <title>DLiteでOS X上にDockerの環境を構築する</title>
    <link rel="alternate" href="http://apatheia.info/blog/2016/02/22/install-dlite/"/>
    <id>http://apatheia.info/blog/2016/02/22/install-dlite/</id>
    <published>2016-02-22T20:54:00+09:00</published>
    <updated>2016-02-22T20:54:00+09:00</updated>
    <author>
      <name>f440</name>
    </author>
    <content type="html">&lt;p&gt;&lt;a href="https://github.com/nlf/dlite"&gt;DLite&lt;/a&gt; をインストールしたので、そのときのメモ。&lt;/p&gt;



&lt;h2 id="dlite"&gt;DLiteとは&lt;/h2&gt;

&lt;p&gt;OS XでDockerを使えるようにやつ。内部では&lt;a href="https://github.com/mist64/xhyve"&gt;xhyve&lt;/a&gt;を使っていて非常にコンパクト。&lt;/p&gt;

&lt;h2 id="section"&gt;作業環境&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;DLite 1.1.3&lt;/li&gt;
  &lt;li&gt;OS X El capitan 10.11.3&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id="section-1"&gt;インストール手順&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;brew install dlite
sudo dlite install # CPUやディスクサイズなどのオプションは`-h`で確認可能
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;おしまい。&lt;/p&gt;

&lt;p&gt;内部では以下が行われる:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code&gt;/etc/sudoers&lt;/code&gt;に&lt;code&gt;dlite,nfs&lt;/code&gt;コマンドをパスワードなしで&lt;code&gt;sudo&lt;/code&gt;できるようにする設定を追加&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;~/Library/LaunchAgents/local.dlite.plist&lt;/code&gt;に起動設定を配置&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;~/.dlite&lt;/code&gt;に起動イメージをダウンロード&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id="section-2"&gt;起動&lt;/h2&gt;

&lt;p&gt;Tmux内で起動しようとするとエラーになるので、必ずTmux外でやること。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;dlite start
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;問題がなければ以下が加えられる:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code&gt;/var/run/docker.sock&lt;/code&gt; にソケットファイルを作成&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;/etc/hosts&lt;/code&gt; にdliteへの参照を追加 (デフォルトは &lt;code&gt;local.docker&lt;/code&gt;。インストール時のオプションで変更可能)&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;/etc/exports&lt;/code&gt; にDLite側のホストへのNFSマウントする設定を追加&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;~/Library/LaunchAgents/local.dlite.plist&lt;/code&gt; をロードし、自動起動するように設定&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;うまくいっていれば、&lt;code&gt;docker -H unix://var/run/docker.sock&lt;/code&gt;(&lt;code&gt;export DOCKER_HOST=unix:///var/run/docker.sock&lt;/code&gt;で指定も可)でdockerが使えるようになる。&lt;/p&gt;

&lt;p&gt;もしうまくいかないようなら、&lt;code&gt;sudo dlite daemon&lt;/code&gt;でコマンドラインから実行して原因を突き止める。とくに、NFS周りのコンフリクトが起きていないかを確認。&lt;/p&gt;

&lt;h2 id="section-3"&gt;まとめ&lt;/h2&gt;

&lt;p&gt;ホストと仮想環境の間がシームレスにつながってcoLinuxっぽさがある。こういうすっきりしたツールは楽しい。&lt;/p&gt;

&lt;h2 id="section-4"&gt;参考&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href="https://github.com/nlf/dlite"&gt;GitHub - nlf/dlite: The simplest way to use Docker on OS X&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://blog.andyet.com/2016/01/25/easy-docker-on-osx/"&gt;Simplifying Docker on OS X&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

</content>
  </entry>
  <entry>
    <title>ISUCON3 の参加記録</title>
    <link rel="alternate" href="http://apatheia.info/blog/2013/11/11/isucon3/"/>
    <id>http://apatheia.info/blog/2013/11/11/isucon3/</id>
    <published>2013-11-11T09:20:00+09:00</published>
    <updated>2013-11-11T09:20:00+09:00</updated>
    <author>
      <name>f440</name>
    </author>
    <content type="html">&lt;p&gt;Web アプリケーションのパフォーマンスコンテスト &lt;a href="http://isucon.net/"&gt;ISUCON 3&lt;/a&gt; に参加し、2 位の成績となった。どのような状態で当日を迎え、どのような作業を行ったのかをまとめる。&lt;/p&gt;



&lt;p&gt;私自身はこれで三度目の ISUCON 参加となるが、今回チームを組むメンバーはみんな初めての参加ということもあり、事前の打ち合わせでは以下のようなことを話していた:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;これまでの大会の説明と典型的なアプローチ
    &lt;ul&gt;
      &lt;li&gt;同時に、過去にとられた戦法は参考程度であること、あくまで現物のアプリケーションを元に戦略を立てるべきでアプリケーションやミドルウェアを事前に決めることは危険であるということは強調&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;よく使われるミドルウェアの概要、メリット/デメリット
    &lt;ul&gt;
      &lt;li&gt;主要機能のほか、キャッシュ部分の永続性の有無（単純に考えればメモリだけで処理してファイルに書き出さない方が早いが、ベンチマークをまたいでキャッシュを引き継げれば切り札になり得る）、キャッシュの時間単位(ベンチマークがフェイルしない限り極力キャッシュしたいという要望を考えると、ミリ秒単位で制御したくなることが多い) などのコンテストで重要となりそうな部分について解説&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;今後問題として取り上げられそうなWebアプリケーションの構成要素
    &lt;ul&gt;
      &lt;li&gt;毎回趣向を凝らした題材が提供されるので完全に予想しきることは不可能だが、Web プログラミングで頻出する要素（予選で言えば「セッション」「ページング」のような単位）を挙げ、他にもどのようなものが考えられるか、どうやって実装できてどのような高速化が行えるかを話し合い&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;予選までに数回休日に集まっては過去の問題を解いたり、自分たちで考えた予想アプリに対してチューニングをしてみたり、もくもく自分なりのトレーニングをしたりする会を開いていた。&lt;/p&gt;

&lt;p&gt;また、個人的には以下のようなことを行ってきた:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;よく目にしているWebアプリケーションの解析
    &lt;ul&gt;
      &lt;li&gt;普段 Web を閲覧しているときでも、どのようなデータ構造が想定されそれをどうやって KVS に乗せるか、画面の構成要素のうちリアルタイムで作る必要がある場所はどこでキャッシュ可能な場所はどこか、といったことを考えるようにする&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;速度に対する感覚を養うため、アプリケーションやミドルウェアのチューニングとその際の効果測定
    &lt;ul&gt;
      &lt;li&gt;自分の日頃扱っているWebアプリケーションではネットワークが飽和するようなアクセスはこないため、限界性能を引き出すような使い方はしていないことが多い。「コンテンツキャッシュでさばいてアプリに届かせないのが定石っス！Nginx とか Varnish っていうのがApacheよりいいらしいっス！」みたいなレベルではなく、アプリケーションと Nginx ではどれくらいの性能差が生まれるのか、Nginx を使うのであれば &lt;a href="http://nginx.org/en/docs/http/ngx_http_proxy_module.html"&gt;proxy_cache&lt;/a&gt; と比べて Unix Domain Socket でMemcached に接続した &lt;a href="https://github.com/agentzh/srcache-nginx-module"&gt;SRCache&lt;/a&gt; ではどれくらい単位時間あたりの処理数が変わるのか、別サーバーにある Memcached と TCP 通信した場合や Redis に変えたときではどのように変わるのか、というようなことを考えられるようにしておく&lt;br /&gt;
ベンチマーク上の最速を求めるということではなく、どういった選択肢が考えられ、それぞれにどのような性能と機能のトレードオフが発生するのかを体にしみつけておく&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;どんなアプリケーションがくるかわからない以上、不安がぬぐいさることはできない。この時点でできることは「当日できるだけ早くウィークポイントを見つけること」、「見つけたウィークポイントに対しての効果的な対応をとれるための引き出しを増やしておくこと」であり、そのための準備をひたすら積み重ねてきた。&lt;/p&gt;

&lt;h2 id="section"&gt;予選&lt;/h2&gt;

&lt;p&gt;予選問題はチームメンバーの勤め先の会議室を借りて取り組んだ。何度も事前打ち合わせで利用していたので、ストレス無く作業に打ち込めた。ただ、興奮しすぎて当日 2 時間くらいしか眠れていない状態だったため、テンションが高いのに頭があんまり働かなくてだいぶつらかった。&lt;/p&gt;

&lt;p&gt;題材はコードスニペット投稿アプリケーション、いわゆる Nopaste や Pastebin と呼ばれるたぐいで &lt;a href="https://gist.github.com/"&gt;Gist&lt;/a&gt; を想像してもらうとわかりやすいと思う。ログインがありセッションが発生すること、公開/プライベートのフラグがあることがこれまでの題材との大きな違いであったが、ある程度予想の範囲内であったことと後述するとおりベンチマークの抜け道に気づけたので、すぐにスコアを伸ばすことができた。&lt;/p&gt;

&lt;p&gt;主な施策は以下の通り:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;インフラ面
    &lt;ul&gt;
      &lt;li&gt;Varnish の配置
        &lt;ul&gt;
          &lt;li&gt;ページキャッシュ。Cookie の値を参照し、ユーザー別にキャッシュを管理することでログイン中のユーザーもキャッシュ対象となるよう設定&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;アプリ面
    &lt;ul&gt;
      &lt;li&gt;markdown -&amp;gt; html の事前変換
        &lt;ul&gt;
          &lt;li&gt;全件 markdown -&amp;gt; html 化したテーブルの dump データを用意しておき、DBクリア後にリストアしようとした&lt;br /&gt;
リストア時間が時間が40秒くらいかかり初期化制限時間60秒をだいぶ圧迫すること(*)、途中から初期データはほぼページキャッシュでさばけるようになっていたので、ここに力をかけるのは無駄だと判定して採用しなかった
            &lt;ul&gt;
              &lt;li&gt;(*) init の間に /var/lib/mysql をまるごと差し替えるなり別のDBにアプリを接続するなりで回避できるので、これ自体はぬるい判断だったと思う&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;更新のないテーブルのインメモリ化や Cookie 内へユーザー情報を登録などで DB 参照回数の低減&lt;/li&gt;
      &lt;li&gt;（チームメンバー担当）クエリの組み方やインデックスの追加などのRDB最適化
        &lt;ul&gt;
          &lt;li&gt;今回のアプリの肝となる部分であり、ひたすら調整を行ってもらっていた&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;（チームメンバー担当）Memcached の参照方法を TCP から Unix Domain Socket に変更
        &lt;ul&gt;
          &lt;li&gt;初期状態では MySQL Memcached Plugin を参照しているので成績が伸びなかったが、こによりトラップを回避してくれた&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;事後の講評などでも抜け穴があったという話があったが、後日公開された&lt;a href="http://isucon.net/archives/32971265.html"&gt;予選のAMI&lt;/a&gt;を利用しても以下のような方法で簡単に確認できる。&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;アプリを  Perl から Ruby に変更 (※ これは単純に自分がRuby に慣れているからで、他の言語では確認していない)&lt;/li&gt;
  &lt;li&gt;Memcached への接続先を MySQL Memcached plugin (ポート 11211) から本当の Memcached (ポート 11212)に変更しアプリケーション起動&lt;/li&gt;
  &lt;li&gt;リバースプロキシの Apache を停止&lt;/li&gt;
  &lt;li&gt;Varnish をインストール&lt;/li&gt;
  &lt;li&gt;以下の設定をして Varnish を起動&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;/etc/varnish/default.vcl&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;backend default { .host = "127.0.0.1"; .port = "5000"; }

sub vcl_recv {
  # POST リクエストやCookieがある(ログイン中)の場合は直接アプリを参照
  if (req.request != "GET" || req.http.Cookie) {
      return (pass);
  }
  return (lookup); # それ以外はキャッシュを探す
}

sub vcl_hash {
    hash_data(req.url);
    hash_data(req.http.host);
    return (hash);
}

sub vcl_fetch {
    set beresp.ttl = 1d; # キャッシュ期間は1日に設定。数字は適当で、とにかく長くしておけばいい
    return (deliver);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;上記設定で初回 workload=1 で 9000 くらい、2 回目に workload=2 で24000くらいでベンチマークが Fail せずに完走することがわかる。Varnish じゃなくて他のコンテンツキャッシュを利用しても同様。&lt;/p&gt;

&lt;p&gt;予選開始直後、Sinatra のアクション単位でリクエスト回数、平均実行時間、ワーストケースの実行時間などの情報がそろえ、いざ Varnish のチューニングを行いはじめたところ、どんなにキャッシュの TTL を伸ばしてもベンチマークが通ってしまうことに気づき思わず吹き出してしまった。&lt;/p&gt;

&lt;p&gt;キャッシュで簡単にスコアが伸ばせることに気づいたのがたしかお昼前で、このあと夕方くらいまで 1 位だったと思う。その後トップは手放すこととなったが、最終的に&lt;a title="ISUCON 本戦出場者決定のお知らせ : ISUCON公式Blog" href="http://isucon.net/archives/32951235.html"&gt;予選5位&lt;/a&gt;で決勝進出を決めることができた。&lt;/p&gt;

&lt;h3 id="section-1"&gt;予選後&lt;/h3&gt;

&lt;p&gt;どうにも簡単に勝てすぎたので本当の自分の実力がどの程度かの不安が残るかたちとなったが、穴を見つけられたのも実力のうちと考えて本戦へ向けての準備を進める。&lt;/p&gt;

&lt;p&gt;予選が割とシンプルで簡単にキャッシュで返せるような作りだったので、本戦はよりアプリケーションよりの対応が求められるはず、そのためにはいままで以上にアプリの状況を把握する能力を高めておく必要がある。*stat 系のパフォーマンス調査ソフトに慣れておいたり、ログ解析のやり方探してみたり（&lt;a href="http://goaccess.prosoftcorp.com/"&gt;GoAccess&lt;/a&gt; 使ったりだとか）、プロファイリング用のソフトウェアを把握しておいたり、調査用&lt;a href="https://gist.github.com/f440/7395268"&gt;アクセスカウンタ&lt;/a&gt; を準備したり、とにかくすぐに分析できるようにしておいた。&lt;/p&gt;

&lt;p&gt;また、予選の際は自分もアプリを改修し、アプリメインのメンバーもインフラ面を考慮してくれていたので、本戦で複数台構成になることにより作業がバッティングすることを懸念された。これについては事前にチーム内でそれぞれにメインとなる作業をお願いして競合しないよう取りはからった。&lt;/p&gt;

&lt;h2 id="section-2"&gt;本戦&lt;/h2&gt;

&lt;p&gt;予選での経験を踏まえ、前日早めに就寝したお陰で当日は体調的には万全、先着で利用可能なミーティングスペースも確保でき順調な滑り出しだった。&lt;/p&gt;

&lt;p&gt;題材は画像投稿版の Twitter で、アップロードした画像ファイルがパブリック/フォロワーのみ/プライベートといった公開範囲に応じて閲覧可能となり、関係するメンバーの投稿が画面に自動反映される SPA (Single Page Application) だった。「ファイルアップロード」「フォロワーのアクティビティがタイムラインに表示」などで、チーム内の感想としては「やっぱりきましたね」、といった感じだったのだが、なによりアプリケーションの出来がよくてびっくりした。&lt;/p&gt;

&lt;p&gt;作業用サーバーとしては、アプリケーションが稼働している 1 台と自由に使える 4 台の計 5 台が与えられた。これまでの ISUCON では CentOS 5 系が使われており、データホテルの Web サイトでもホスティングしている VPS の OS CentOS 5.8 となっているので CentOS 5 系が来る可能性も考慮していたのだが、今回は CentOS 6.4 であった。&lt;/p&gt;

&lt;p&gt;サーバー受け取り後、バックアップをとりつつアプリケーションのプロファイリングを進めるが、どう見ても画像変換のコストだけが突出していることがわかる。データベースへのアクセスはきわめて短時間で終わっており、ボトルネックではない以上手をかけるのは無駄だと判断した。&lt;/p&gt;

&lt;p&gt;状況確認を踏まえ、以下のような作業を行っていった:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;事前に初期データのアイコンおよび投稿画像はリサイズをかけておく
    &lt;ul&gt;
      &lt;li&gt;バックアップとしてローカルに全ファイルを転送していたので、そのファイルを変換して本番環境に書き戻し
        &lt;ul&gt;
          &lt;li&gt;うっかりリサイズのサイズ間違えたり、そんなに早くない自分のマシン(Macbook Air)で実行していたので、かなりの時間がかかってしまった&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;画像のうち、誰でも閲覧可能なファイルは Web サーバーから直接配信できるよう、公開領域にシンボリックリンクを作成
    &lt;ul&gt;
      &lt;li&gt;全ユーザーと全ファイルのアクセス権限を組み合わせてリンクを作成し、アクセス権限をDBに問い合わせずにレスポンスを返すというのもアイデアとしてはあったのだが、時間がかかるのでこのようにした&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;（チームメンバー担当）画像変換時にファイルシステムへファイルを保存。また画像表示時に変換済みファイルがないかのチェックを追加&lt;/li&gt;
  &lt;li&gt;（チームメンバー担当）ファイルシステムに保存したタイミングで、リサイズを非同期処理で実施
    &lt;ul&gt;
      &lt;li&gt;負荷が高くなってくるとこの部分が詰まってしまい、変換待ちが大量にたまるのであまり効率的ではなく、不採用&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;最終的に以下の構成で計測を迎えた。フロント 4 台に Nginx を配置のうえ &lt;code&gt;try_files&lt;/code&gt; でローカルにファイルがあるかどうかをチェックし、なければバックエンドサーバーに処理を委譲するようになっている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;                +----------+        +----------------+
  Benchmark -&amp;gt;  | Web x 4  |  ----  | Web + App + DB |
                +----------+        +----------------+
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;時間がなくてこのようなかたちとなったが、今考えてもこれがよかったかどうかでいえばまったくもってよくなかった。完全にバックエンドのアプリサーバーが負荷でつぶれていたが、全サーバーでアプリを動かせばきれいに台数分スケールしていたはずだったのに、本当に悔やまれる。&lt;/p&gt;

&lt;p&gt;タイムアップ時点ではそれほどの成績ではなかったが、本戦のベンチマークを無事乗り越え、気づいたら 2 位という成績で ISUCON 3 の幕を閉じた。&lt;/p&gt;

&lt;h2 id="section-3"&gt;ふりかえって&lt;/h2&gt;

&lt;p&gt;正攻法ではない方法もいろいろ考えてはいたんだけど、結局のところ他のチームと比べても過激な改修は行わずに済ませた。直しやすそうなところ、目のつきやすいところではなく、手早く確実にウィークポイントを直すというのが目標だったので、それは実現できたんだと思う。&lt;/p&gt;

&lt;p&gt;けどやっぱり優勝できなかったのは心残りで、試合終了後や帰宅後のチャット上でもチームメンバーと「非同期のワーカー作る時間の無駄だった」とか「どう考えてもアプリサーバーネックだったし、他の4台でもアプリ動かしてベンチマークのワーカー増やせばトップとれたんじゃないの」とか「Macbook Air でちまちま画像変換するの失敗だった」とか、いろいろ話をしていた。1位があまりに鮮烈で、それ以外の順位は空気みたいな存在だし、やはりこの世はトップ総取りなのだなぁ、と痛感した。&lt;/p&gt;

&lt;p&gt;毎回このような場を用意していただいている LINE 社、データホテル社の方々には感謝の限りです。お弁当おいしゅうございました。出題のカヤックの皆さんもすばらしい問題をありがとうございました。&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>Immutable Infrastracture について</title>
    <link rel="alternate" href="http://apatheia.info/blog/2013/08/10/immutable-infrastructure/"/>
    <id>http://apatheia.info/blog/2013/08/10/immutable-infrastructure/</id>
    <published>2013-08-10T21:00:00+09:00</published>
    <updated>2013-08-10T21:00:00+09:00</updated>
    <author>
      <name>f440</name>
    </author>
    <content type="html">&lt;p&gt;ここ最近話題に上がることが多い Immutable Infrastracture と、その他仮想環境周りについての雑感。&lt;/p&gt;



&lt;p&gt;Immutable Server や Immutable Infrastracture っていう単語がいろんなところで目に入るようになった。とくに Chad Fowler が&lt;a href="http://chadfowler.com/blog/2013/06/23/immutable-deployments/"&gt;ブログで取り上げたり&lt;/a&gt;、&lt;a href="http://foodfightshow.org/2013/07/immutable-infrastructure.html"&gt;Food Fight に出たり&lt;/a&gt; して、世間でも関心が高まった感じがある。&lt;/p&gt;

&lt;p&gt;プログラムを書く人にはご存じの通り、この Immutable っていうのは状態が変更出来ないことを指している。Immutable な Infrastracture っていうのは、ざっくり言うと「運用中のサーバーに変更を加えない」っていうアプローチでサーバーを管理しているスタイルのこと。&lt;/p&gt;

&lt;p&gt;(ファイルシステムを読み取り専用にする、とかそういう話じゃなくて、あくまでそういう方針でやろうっていう話)&lt;/p&gt;

&lt;p&gt;サーバーの設定を変更したくなったら、その変更を加えた新しいサーバーを用意する。アプリケーションをデプロイしたくなったら、新しくサーバーを立ち上げてそちらにデプロイを行う。稼働中のサーバーに SSH でログインして設定を変更するようなことはせず、なにかしらの変更のためにはつねにサーバーを追加していく。サービスを新サーバー群にで行うように DNS を切り替えたあと、参照されなくなったサーバーは破棄する(まるでガベージコレクションみたいだね)。&lt;/p&gt;

&lt;h2 id="immutable-infrastracture-"&gt;どうやって Immutable Infrastracture を実現するのか&lt;/h2&gt;

&lt;p&gt;Immutable Infrastracture には、いわゆる &lt;a href="http://martinfowler.com/bliki/BlueGreenDeployment.html"&gt;Blue Green Deployment&lt;/a&gt; で知られているテクニックを用いる。&lt;/p&gt;

&lt;p&gt;現在、プラットフォームとして上手に Immutable Infrastracture を実現できているのは &lt;a href="http://aws.amazon.com/jp/elasticbeanstalk/"&gt;AWS Elastic Beanstalk&lt;/a&gt; だと思っているので、これを例に説明する。Elastic Beanstalk を「あー、AWS がやってる heroku 的なアレだろ」くらいの認識しかなければ、一度ちゃんと調べてみたほうがいい。&lt;/p&gt;

&lt;p&gt;Elastic Beanstalk では、ロードバランサーとそこにぶら下がるサーバー群 (オートスケールするので、台数は伸び縮みする) が「環境(Envirnment)」というくくりで管理される。&lt;/p&gt;

&lt;p&gt;サーバーには Amazon が用意したマシンイメージを使うこともできるし、カスタマイズしたイメージを利用することも可能になっている。アプリケーションのデプロイは git push だったり、Java の war ファイルアップロードでできるので、サーバーにログインする必要はない。&lt;/p&gt;

&lt;p&gt;「環境」にはそれぞれ URL が割り振られるのだが、これは環境間ですげ替えることができる。つまり、検証環境でアプリをデプロイしたりミドルウェアの設定変更をして、確認がとれたら本番環境と入れ替えたり、問題が起きたらすぐに元に戻したりといったことがダウンタイムなく行える。&lt;/p&gt;

&lt;p&gt;Netflix のデプロイツール &lt;a href="https://github.com/Netflix/asgard"&gt;asgard&lt;/a&gt; も同じようなことをしているし、Heroku の &lt;a href="https://devcenter.heroku.com/articles/labs-preboot/"&gt;preboot&lt;/a&gt; も内部では同じようなことやってるんじゃないかな。(追記: Heroku の Preboot だけど、説明ページへのリンクがなくなっている。今は &lt;a href="https://devcenter.heroku.com/articles/labs-pipelines"&gt;Pipelines&lt;/a&gt; 使えってことかも)&lt;/p&gt;

&lt;p&gt;もちろん、オンプレミスに自前の環境でこういったことを行うことも可能だろうけど、アプリケーションの切り替えに DNS の設定変更なり浮動 IP アドレスの付け替えなりが必要となってくるので、かなり面倒くさい。すでにシステムとして提供されているものを利用できるのであれば、それを使うのが現実的だとは思う。&lt;/p&gt;

&lt;h2 id="section"&gt;構成管理ツールの役割&lt;/h2&gt;

&lt;p&gt;設定を変更するためだけに新しいマシンを作るだなんて、なんでそんなことをするのだろうと Chef や Puppet などのツールを使って変更管理している人たちは不思議に思うかもしれない。発想を逆にしてみると、仮想マシンが状態を持っているから冪等性だとか自己修復性を考慮したセットアップツールが必要になる。仮想マシンが不変だという前提にたてば、こういった処理が省けるようになるのかもしれない。&lt;/p&gt;

&lt;p&gt;とはいえ、Immutable Infrastracture を実践したとしても構成管理ツールは以下のような局面で今後も使われていくことになるだろうと思う。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;ベースとなる仮想マシンのセットアップのため&lt;/li&gt;
  &lt;li&gt;初回起動後の仮想マシンに対して、(仮想マシンに組み込めない or 組み込みたくない) マシンごとの変更を設定するため&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;個人的には、今の Chef や Puppet みたいなサーバー/クライアント構成は必要なくて、もっとライトウェイトなもので十分な気がしている。&lt;/p&gt;

&lt;h2 id="section-1"&gt;仮想マシンの役割&lt;/h2&gt;

&lt;p&gt;昨今の構成管理ツールブームで、サーバーセットアップの技術が成熟してきた。こういったツールをソフトウェアでいうところの autotools や ant といったビルドツールにたとえるなら、次の興味は apt や rpm といったパッケージにあたるもの、つまりセットアップ済み仮想マシンになるかと思う。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Packer は仮想マシンの作成手順や作成先を抽象化しようとしている&lt;/li&gt;
  &lt;li&gt;Docker は仮想マシンをまるで Github から clone するかのように共有する方法を提供している&lt;/li&gt;
  &lt;li&gt;AWS MarketPlace は個人/企業に仮想マシンを売り買いできる仕組みを提供している&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;最近のプロダクトやサービスを考えてみても、仮想マシン自体の取り扱いにだんだん関心がむかっているのは確かっぽい。Immutable Infrastracture もまた、仮想マシンを仮想マシンらしく扱った運用形態といえるんじゃないかな。&lt;/p&gt;

&lt;h2 id="section-2"&gt;参考&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href="http://martinfowler.com/bliki/ImmutableServer.html"&gt;ImmutableServer&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="http://www.thoughtworks-studios.com/blog/rethinking-building-cloud-part-4-immutable-servers"&gt;Rethinking building on the cloud: Part 4: Immutable Servers&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="http://chadfowler.com/blog/2013/06/23/immutable-deployments/"&gt;Trash Your Servers and Burn Your Code: Immutable Infrastructure and Disposable Components - Chad Fowler&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</content>
  </entry>
  <entry>
    <title>ブログエンジンを Octopress から Middleman に変えた</title>
    <link rel="alternate" href="http://apatheia.info/blog/2013/08/10/octopress-to-middleman/"/>
    <id>http://apatheia.info/blog/2013/08/10/octopress-to-middleman/</id>
    <published>2013-08-10T20:30:00+09:00</published>
    <updated>2013-08-10T20:30:00+09:00</updated>
    <author>
      <name>f440</name>
    </author>
    <content type="html">&lt;p&gt;このサイトは今まで &lt;a href="http://octopress.org/"&gt;Octopress&lt;/a&gt; を使って生成していたんだけど、&lt;a href="http://middlemanapp.com/"&gt;Middleman&lt;/a&gt; に変えてみた。&lt;/p&gt;



&lt;p&gt;元々 Octopress の設定ファイルの書き方とかがモヤモヤするものがあって(Rakefile に設定項目埋め込んであるところとか) Jekyll にしようかなと思ったんだけど、なんとなく Middleman にしてみた。その後の感想など。&lt;/p&gt;

&lt;p&gt;(もう2ヶ月くらい前の話なので、移行当時の記憶はおぼろげ)&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;ビルド時間が短くなった
    &lt;ul&gt;
      &lt;li&gt;素の jekyll はビルド早いんだけど、Octopress は結構遅いんで気になっていた。middleman は Octopress よりかは早い&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;ブログの内容はほぼそのまま使い回せた
    &lt;ul&gt;
      &lt;li&gt;メタデータ部分を s/categories/tags/ で置換したくらいだったと思う&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;公開されているテンプレートが少ない
    &lt;ul&gt;
      &lt;li&gt;自分でちまちま書いてる&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;middleman-livereload が便利
    &lt;ul&gt;
      &lt;li&gt;&lt;a href="https://github.com/johnbintz/rack-livereload"&gt;rack-livereload&lt;/a&gt; を使っている。ブラウザに拡張を入れなくても、Web Socket でリロードしてくれる。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href="https://github.com/rtomayko/tilt"&gt;tilt&lt;/a&gt; を使っているので、テンプレートエンジンは自由に選択できる
    &lt;ul&gt;
      &lt;li&gt;楽しくなって、&lt;a href="http://slim-lang.com/"&gt;Slim&lt;/a&gt; を使って &lt;a href="https://github.com/shower/shower"&gt;shower&lt;/a&gt; を &lt;a href="https://github.com/f440/middleman-miwer"&gt;移植してみたりした&lt;/a&gt;。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;おおむね満足です。&lt;/p&gt;

&lt;h2 id="section"&gt;参考&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href="http://octopress.org/"&gt;Octopress&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="http://middlemanapp.com/"&gt;Middleman&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://github.com/rtomayko/tilt"&gt;tilt&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

</content>
  </entry>
  <entry>
    <title>仮想環境構築に docker を使う</title>
    <link rel="alternate" href="http://apatheia.info/blog/2013/06/17/docker/"/>
    <id>http://apatheia.info/blog/2013/06/17/docker/</id>
    <published>2013-06-17T09:13:00+09:00</published>
    <updated>2013-06-17T09:13:00+09:00</updated>
    <author>
      <name>f440</name>
    </author>
    <content type="html">&lt;p&gt;ちょっと前から &lt;a href="http://www.docker.io/"&gt;Docker&lt;/a&gt; を使っているので、その話。&lt;/p&gt;



&lt;h2 id="dockr-"&gt;Dockr について&lt;/h2&gt;

&lt;p&gt;&lt;a href="http://www.docker.io/"&gt;Docker&lt;/a&gt; は &lt;a href="https://www.dotcloud.com/"&gt;dotcloud&lt;/a&gt; がオープンソースで公開している、コンテナ技術による仮想化ソフトウェア。&lt;/p&gt;

&lt;p&gt;以下のテクノロジーベースにしている:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href="http://lxc.sourceforge.net/"&gt;LXC&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;a href="/blog/2012/05/13/vps-lxc-xtradb-cluster/"&gt;前にも書いた&lt;/a&gt;。Xen とか VirtualBOX みたいにホスト内に仮想マシンを立ち上げるんじゃなくて、ホスト内の隔離された環境で仮想マシンを動かす技術。物理マシンをシミュレーションしているんじゃないってことは、VPS とか EC2 とかの仮想マシン上でも問題なく動くし、マシンを起動するプロセスが不要となるので、一瞬で使い始められるというメリットにつながっている。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href="http://aufs.sourceforge.net/"&gt;AUFS&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;UnionFS(ディレクトリを重ね合わせることができる)の実装の一つ。元の仮想マシンイメージを書き換えないで、更新が発生した部分は別の場所に書き込んでいくようになっている。これにより、仮想マシンの立ち上げ時にイメージのコピーが発生しないので、すぐに使い始められる。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Docker を使う前は LXC のラッパーとして取っつきにくさを緩和してくれる、とかそういうレベルだと思ったんだけど、予想はよい方向に裏切られた。&lt;/p&gt;

&lt;p&gt;&lt;a href="http://docs.docker.io/en/latest/commandline/command/images/"&gt;仮想マシンのイメージを可視化したもの&lt;/a&gt;を見ると、まるで Git のコミットログみたいに見えると思う。実際、情報は差分で管理され、履歴を残したり分岐させたりといった操作が非常に軽量にできていて、Git を操作するかのように仮想マシンを操作できるようになっている。&lt;/p&gt;

&lt;h2 id="section"&gt;動かし方&lt;/h2&gt;

&lt;p&gt;Arch Linux や Debian で動かしている人がいるみたいだけど、公式サポートは今のところ Ubuntu のみ。Ubuntu 12.04 LTS を使っているのであれば、&lt;code&gt;curl get.docker.io | sh -x&lt;/code&gt; で動くようになる。&lt;/p&gt;

&lt;p&gt;ちゃんとしたやり方は &lt;a href="http://docs.docker.io/en/latest/installation/"&gt;ドキュメント&lt;/a&gt;を見れば、特にはまることもないと思う。できるだけ新しい Ubuntu を使っておけばいい。&lt;/p&gt;

&lt;p&gt;すぐに試してみたいんなら、Vagrant 経由で簡単に使い始められる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;git clone https://github.com/dotcloud/docker.git
cd docker
vagrant up --provider virtualbox # or vagrant up --provider aws
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id="section-1"&gt;基礎的な操作方法&lt;/h2&gt;

&lt;p&gt;インストールがうまくいって Docker が起動しているものとして、早速使ってみる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker
Usage: docker [OPTIONS] COMMAND [arg...]
  -H="127.0.0.1:4243": Host:port to bind/connect to

  A self-sufficient runtime for linux containers.

  Commands:
  attach    Attach to a running container
  build     Build a container from a Dockerfile
  commit    Create a new image from a container's changes
(以下省略)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;コマンドがずらっと表示されるかと思う。まずは単発のコマンドをコンテナ内で実行してみる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker run base /bin/echo hi
Pulling repository base from https://index.docker.io/v1
Pulling image b750fe79269d2ec9a3c593ef05b4332b1d1a02a62b4accb2c21d589ff2f5f2dc (latest) from base
Pulling b750fe79269d2ec9a3c593ef05b4332b1d1a02a62b4accb2c21d589ff2f5f2dc metadata
Pulling b750fe79269d2ec9a3c593ef05b4332b1d1a02a62b4accb2c21d589ff2f5f2dc fs layer
Downloading 10240/? (n/a)
Pulling 27cf784147099545 metadata
Pulling 27cf784147099545 fs layer
Downloading 94863360/? (n/a)
Pulling image 27cf784147099545 () from base
hi
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;「&lt;code&gt;docker&lt;/code&gt; コマンドに run サブコマンドを指定して、&lt;code&gt;base&lt;/code&gt; という仮想マシンで &lt;code&gt;/bin/echo hi&lt;/code&gt; コマンドを実行する」という意味になる。仮想マシンがダウンロードされるが、これは初回実行時のみ。最後に表示された「hi」というのが今回の実行結果で、このコンテナの役割はこれで終わり。&lt;/p&gt;

&lt;p&gt;今度は作ったマシンの中に入ってみるために、&lt;code&gt;-i&lt;/code&gt; と &lt;code&gt;-t&lt;/code&gt; オプションで入出力できるようにして &lt;code&gt;/bin/bash&lt;/code&gt; を起動してみる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker run -i -t base /bin/bash
root@bc43a290f0ce:/#
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;端末から抜けるとホスト側に制御が戻る。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;root@bc43a290f0ce:/# exit
exit
$
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;今度は &lt;code&gt;-d&lt;/code&gt; オプションでコマンドを実行しっぱなしにする。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker run -i -t -d base /bin/ping -i 5 www.aikatsu.net
79365b2985c4
$
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ID が返されて、すぐに端末が利用可能になる。稼働中のプロセスを確認してみる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker ps
ID                  IMAGE               COMMAND                CREATED             STATUS              PORTS
79365b2985c4        base:latest         /bin/ping -i 5 www.a   22 seconds ago      Up 21 seconds
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;次に実行中の出力をのぞいてみよう。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker logs 79365b2985c4
PING www.aikatsu.net (60.32.7.37) 56(84) bytes of data.
64 bytes from www3.sunrise-anime.jp (60.32.7.37): icmp_req=1 ttl=49 time=282 ms
64 bytes from www3.sunrise-anime.jp (60.32.7.37): icmp_req=3 ttl=49 time=278 ms
64 bytes from www3.sunrise-anime.jp (60.32.7.37): icmp_req=4 ttl=49 time=283 ms
64 bytes from www3.sunrise-anime.jp (60.32.7.37): icmp_req=5 ttl=49 time=266 ms
64 bytes from www3.sunrise-anime.jp (60.32.7.37): icmp_req=6 ttl=49 time=268 ms
64 bytes from www3.sunrise-anime.jp (60.32.7.37): icmp_req=8 ttl=49 time=264 ms
64 bytes from www3.sunrise-anime.jp (60.32.7.37): icmp_req=9 ttl=49 time=270 ms
64 bytes from www3.sunrise-anime.jp (60.32.7.37): icmp_req=10 ttl=49 time=290 ms
64 bytes from www3.sunrise-anime.jp (60.32.7.37): icmp_req=11 ttl=49 time=284 ms
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;順調に動き続けているようなので、このジョブにアタッチしてみる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker attach 79365b2985c4
64 bytes from www3.sunrise-anime.jp (60.32.7.37): icmp_req=18 ttl=49 time=239 ms
64 bytes from www3.sunrise-anime.jp (60.32.7.37): icmp_req=19 ttl=49 time=291 ms
64 bytes from www3.sunrise-anime.jp (60.32.7.37): icmp_req=20 ttl=49 time=275 ms
(出力が続く)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;アタッチ中の端末は &lt;code&gt;Ctrl-p Ctrl-q&lt;/code&gt; でデタッチできる。(このとき use of closed network connection っていうエラーが出る場合 Ctrl-c で抜けるしかないっぽい。バグレポートは上がっているので、じきに直ると思う。)&lt;/p&gt;

&lt;p&gt;最後に&lt;code&gt;kill&lt;/code&gt;でこのプロセスを消してみる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker kill 79365b2985c4
$ docker ps
$
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;ps&lt;/code&gt;からプロセスが消えた。基礎的なコンテナの操作の説明は以上。&lt;/p&gt;

&lt;h2 id="section-2"&gt;詳細&lt;/h2&gt;

&lt;h3 id="section-3"&gt;コンテナ&lt;/h3&gt;

&lt;p&gt;これまでコマンドを実行したり、&lt;code&gt;kill&lt;/code&gt; されたコンテナはどうなっているのか。実は全部残っている。停止したコンテナを表示するために&lt;code&gt;-a&lt;/code&gt;をつける。ついでに、情報を省略しないで表示するために&lt;code&gt;-notrunc&lt;/code&gt; もつける。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker ps -a -notrunc
ID                                                                 IMAGE               COMMAND                          CREATED             STATUS              PORTS
79365b2985c43a2a6977764f4dde2d375084020fbc04cc855508c417a36f88c2   base:latest         /bin/ping -i 5 www.aikatsu.net   14 minutes ago      Exit 0
bc43a290f0ced4677ee7eb1a0d662cca496cc720d8db20e746dda45e4659f503   base:latest         /bin/bash                        16 minutes ago      Exit 0
7a666192cca72cea81cade398b22700c982fbb9271a7eca23ff51c6c504d5971   base:latest         /bin/echo hi                     16 minutes ago      Exit 0
8b0af4fc390d762c33dadc1b149516ba95bdb70d093e991ec2df563817f55ffb   base:latest         /bin/bash                        21 minutes ago      Exit 0
4637bc6341706c25e066c5ccfe92e10c923bfe4955a9e8b3ce07237fda0fb34a   base:latest         /bin/echo hi                     21 minutes ago      Exit 0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;正常終了しているので、すべて&lt;code&gt;Exit 0&lt;/code&gt;になっている。また、ID は省略表記されていたこともわかる。コンテナの実体は &lt;code&gt;/var/lib/docker/containers/&amp;lt;ID&amp;gt;&lt;/code&gt; 以下に格納されている。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ sudo ls /var/lib/docker/containers/
4637bc6341706c25e066c5ccfe92e10c923bfe4955a9e8b3ce07237fda0fb34a
79365b2985c43a2a6977764f4dde2d375084020fbc04cc855508c417a36f88c2
7a666192cca72cea81cade398b22700c982fbb9271a7eca23ff51c6c504d5971
8b0af4fc390d762c33dadc1b149516ba95bdb70d093e991ec2df563817f55ffb
bc43a290f0ced4677ee7eb1a0d662cca496cc720d8db20e746dda45e4659f503
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;どんどんたまっていくから心配かもしれないけど、各コンテナはベースイメージからの差分しかもたないので、問題にならない。もし、消したくなったら &lt;code&gt;docker rm &amp;lt;コンテナのID&amp;gt;&lt;/code&gt; で消せる。&lt;/p&gt;

&lt;p&gt;作業領域であったコンテナを &lt;code&gt;commit&lt;/code&gt; するとイメージとして使い回せるようになる。&lt;code&gt;ユーザー名/名称&lt;/code&gt;にするのが作法っぽい。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker commit -m "My first container" 4637bc634170 f440/first_container
02036952e5dc
$ docker images
REPOSITORY             TAG                 ID                  CREATED
base                   latest              b750fe79269d        12 weeks ago
base                   ubuntu-quantl       b750fe79269d        12 weeks ago
base                   ubuntu-quantal      b750fe79269d        12 weeks ago
base                   ubuntu-12.10        b750fe79269d        12 weeks ago
f440/first_container   latest              02036952e5dc        3 seconds ago
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これで今後は &lt;code&gt;docker run f440/first_container&lt;/code&gt; をベースにしたコンテナを作れるようになる。&lt;/p&gt;

&lt;h3 id="section-4"&gt;イメージ&lt;/h3&gt;

&lt;p&gt;もう一回イメージの一覧を内容を確認してみよう。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker images
REPOSITORY             TAG                 ID                  CREATED
f440/first-container   latest              141fef9a2f57        14 seconds ago
base                   latest              b750fe79269d        12 weeks ago
base                   ubuntu-12.10        b750fe79269d        12 weeks ago
base                   ubuntu-quantl       b750fe79269d        12 weeks ago
base                   ubuntu-quantal      b750fe79269d        12 weeks ago
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;base イメージは latest, ubuntu-quantl, ubuntu-quantal, ubuntu-12.10 といった複数のタグがついていることがわかる。イメージは複数の名称をタグ付けできるようになっており、&lt;code&gt;base:latest&lt;/code&gt;, &lt;code&gt;base:ubuntu-12.10&lt;/code&gt; といった形で異なるイメージを呼び出せるようになっている。省略時は &lt;code&gt;base:latest&lt;/code&gt; と同じ。&lt;/p&gt;

&lt;p&gt;pull してくるイメージは &lt;a href="https://index.docker.io/"&gt;https://index.docker.io/&lt;/a&gt; から情報を持ってくる。コマンドラインで検索したい場合は &lt;code&gt;search&lt;/code&gt; コマンドを利用する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker search centos
Found 4 results matching your query ("centos")
NAME                          DESCRIPTION
centos
backjlack/centos-6.4-x86_64
creack/centos
mbkan/lamp                    centos with ssh, LAMP, PHPMyAdmin(root pas...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ローカルにキャッシュされたイメージを消すには &lt;code&gt;docker rmi &amp;lt;イメージのID&amp;gt;&lt;/code&gt;でいい。&lt;/p&gt;

&lt;p&gt;自前で作ったイメージを &lt;a href="https://index.docker.io/"&gt;https://index.docker.io/&lt;/a&gt;  に登録するには、あらかじめサイト上でアカウントを作っておき、 &lt;code&gt;docker login&lt;/code&gt; した後に &lt;code&gt;docker push&lt;/code&gt; する。イメージ名にアンダーバー使っていると &lt;code&gt;push&lt;/code&gt; で失敗するのと、アップロードしたイメージを消す機能がまだなかったりするので注意。&lt;/p&gt;

&lt;p&gt;イメージの実体は &lt;code&gt;/var/lib/docker/graph/&lt;/code&gt; にある。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker images -a -notrunc
REPOSITORY          TAG                 ID                                                                 CREATED
base                latest              b750fe79269d2ec9a3c593ef05b4332b1d1a02a62b4accb2c21d589ff2f5f2dc   12 weeks ago
base                ubuntu-12.10        b750fe79269d2ec9a3c593ef05b4332b1d1a02a62b4accb2c21d589ff2f5f2dc   12 weeks ago
base                ubuntu-quantl       b750fe79269d2ec9a3c593ef05b4332b1d1a02a62b4accb2c21d589ff2f5f2dc   12 weeks ago
base                ubuntu-quantal      b750fe79269d2ec9a3c593ef05b4332b1d1a02a62b4accb2c21d589ff2f5f2dc   12 weeks ago
&amp;lt;none&amp;gt;              &amp;lt;none&amp;gt;              27cf784147099545                                                   12 weeks ago

$ sudo ls -1 /var/lib/docker/graph
141fef9a2f57e86dd6d9aa58fe9318b0d9d71d91053079842051d9738bad6e45
27cf784147099545
b750fe79269d2ec9a3c593ef05b4332b1d1a02a62b4accb2c21d589ff2f5f2dc
checksums
:tmp:
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ここで images に ID: 27cf784147099545 というのが現れた。これは何か。&lt;code&gt;inspect&lt;/code&gt; を使うとイメージの詳細を表示できる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker inspect base
{
    "id": "b750fe79269d2ec9a3c593ef05b4332b1d1a02a62b4accb2c21d589ff2f5f2dc",
    "parent": "27cf784147099545",
    "created": "2013-03-23T22:24:18.818426-07:00",
    "container": "3d67245a8d72ecf13f33dffac9f79dcdf70f75acb84d308770391510e0c23ad0",
    "container_config": {
        "Hostname": "",
        "User": "",
        "Memory": 0,
        "MemorySwap": 0,
        "CpuShares": 0,
        "AttachStdin": false,
        "AttachStdout": false,
        "AttachStderr": false,
        "PortSpecs": null,
        "Tty": true,
        "OpenStdin": true,
        "StdinOnce": false,
        "Env": null,
        "Cmd": [
            "/bin/bash"
        ],
        "Dns": null,
        "Image": "base",
        "Volumes": null,
        "VolumesFrom": ""
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ID: 27cf784147099545 は base イメージの親イメージの ID であることがわかる。イメージは差分になっているので、親のイメージが必要ということで初回実行のタイミングで base と一緒に 27cf784147099545 もダウンロードされていたのだった。&lt;/p&gt;

&lt;h3 id="section-5"&gt;ネットワーク&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;docker run&lt;/code&gt; 時に &lt;code&gt;-p&lt;/code&gt; をつけることで、コンテナから外部にさらすポートを決められる。コンテナ側のポートはホスト側のポートに変換される際、ポート番号が変更される(49153以降になる)ので、&lt;code&gt;docker port &amp;lt;ジョブのID&amp;gt; &amp;lt;ポート番号&amp;gt;&lt;/code&gt; あるいは &lt;code&gt;docker ps &lt;/code&gt; でポートの対応状況を確認する必要がある。&lt;/p&gt;

&lt;p&gt;ドキュメントの &lt;a href="https://github.com/dotcloud/docker#expose-a-service-on-a-tcp-port"&gt;Expose a service on a TCP port&lt;/a&gt; がわかりやすい。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# 以下、コメントは書き換えてある
# また、途中経過がわかりやすいように set -x しておく
set -x

# 4444 を晒すよう -p オプションをつけて docker run しつつ、
# コンテナは netcat で4444を待ち受ける
JOB=$(docker run -d -p 4444 base /bin/nc -l -p 4444)
++ docker run -d -p 4444 base /bin/nc -l -p 4444
+ JOB=c86c892574f7

# 4444 がローカルのどのポートに対応するのか確認
# docker ps でも調べることはできる
PORT=$(docker port $JOB 4444)
++ docker port c86c892574f7 4444
+ PORT=49166

# ルーティングによっては localhost とか 127.0.0.1 だと
# うまくいかないことがあるので、eth0 のIPアドレスを使おう、
# ってことらしい
IP=$(ifconfig eth0 | perl -n -e 'if (m/inet addr:([\d\.]+)/g) { print $1 }')
++ perl -n -e 'if (m/inet addr:([\d\.]+)/g) { print $1 }'
++ ifconfig eth0
+ IP=10.156.137.111
echo hello world | nc $IP $PORT
+ nc 10.156.137.111 49166
+ echo hello world

# コンテナが受信したメッセージを logs で表示
echo "Daemon received: $(docker logs $JOB)"
++ docker logs c86c892574f7
+ echo 'Daemon received: hello world'
Daemon received: hello world
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id="dockerfile"&gt;Dockerfile&lt;/h3&gt;

&lt;p&gt;DSLで書かれた設定(通常ファイル名は&lt;code&gt;Dockerfile&lt;/code&gt;とする)をあらかじめ用意することで、手順に従ってイメージを作ることができる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;読み込ませ方 (1)
docker build &amp;lt;Dockerfileのあるディレクトリ&amp;gt;
# ex. docker build .

読み込ませ方 (2)
docker build -
# ex. docker build - &amp;lt; /foo/bar/Dockerfile
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Dockerfile の例&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;FROM base
RUN /bin/echo hi
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;これで、&lt;code&gt;docker build&lt;/code&gt; すれば &lt;code&gt;docker run base /bin/echo hi&lt;/code&gt; と同じ効果が得られる。&lt;/p&gt;

&lt;p&gt;指定できるはコマンドは以下の通り。大文字小文字は区別しないけど、引数と見分けやすいように大文字が使われる。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code&gt;FROM &amp;lt;image&amp;gt;&lt;/code&gt; ベースとなるイメージを指定&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;MAINTAINER &amp;lt;name&amp;gt;&lt;/code&gt; メンテナの名前を指定&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;RUN &amp;lt;command&amp;gt;&lt;/code&gt; ビルド中に実行したいコマンドを指定&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;CMD &amp;lt;command&amp;gt;&lt;/code&gt; 起動後のコンテナで実行したいコマンドを指定&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;EXPOSE &amp;lt;port&amp;gt; [&amp;lt;port&amp;gt; ...]&lt;/code&gt; 外部に晒すポートの指定&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;ENV &amp;lt;key&amp;gt; &amp;lt;value&amp;gt;&lt;/code&gt; 環境変数の設定&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;INSERT &amp;lt;file url&amp;gt; &amp;lt;path&amp;gt;&lt;/code&gt; deprecated なので ADD を利用すること&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;ADD &amp;lt;src&amp;gt; &amp;lt;dest&amp;gt;&lt;/code&gt; ファイルを配置&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code&gt;RUN&lt;/code&gt; と &lt;code&gt;CMD&lt;/code&gt; の違いがわかりにくいかもしれない。例を出す。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# RUN, CMD で指定したコマンドが実行されたとき、
# 標準出力と /tmp/*.log に記録を残す

$ cat &amp;lt;&amp;lt;SCRIPT &amp;gt;Dockerfile
&amp;gt; FROM base
&amp;gt; RUN /bin/echo run | tee /tmp/run.log
&amp;gt; CMD /bin/echo cmd | tee /tmp/cmd.log
&amp;gt; SCRIPT

# ビルドの実行

$ docker build .
Caching Context 10240/? (n/a)
FROM base ()
===&amp;gt; b750fe79269d2ec9a3c593ef05b4332b1d1a02a62b4accb2c21d589ff2f5f2dc
RUN /bin/echo run | tee /tmp/run.log (b750fe79269d2ec9a3c593ef05b4332b1d1a02a62b4accb2c21d589ff2f5f2dc)
===&amp;gt; d10b6bd1321d45b0228b5741c01d1f76fd0288052e56836609f9bdf217854f3d
CMD /bin/echo cmd | tee /tmp/cmd.log (d10b6bd1321d45b0228b5741c01d1f76fd0288052e56836609f9bdf217854f3d)
===&amp;gt; 60671e9969185841032fb02f623917672c4f871a6be68e5aa575e8fdf1f94229
Build successful.
===&amp;gt; 60671e9969185841032fb02f623917672c4f871a6be68e5aa575e8fdf1f94229

# run, cmd の実行結果を確認
# =&amp;gt; run だけが実行されている

$ docker run 60671e99691 /bin/ls /tmp/
run.log

# イメージを inspect する
# =&amp;gt; どうやらコンテナは記憶していることがわかる

$ docker inspect 60671e99691
{
    "id": "60671e9969185841032fb02f623917672c4f871a6be68e5aa575e8fdf1f94229",
    "parent": "d10b6bd1321d45b0228b5741c01d1f76fd0288052e56836609f9bdf217854f3d",
    "created": "2013-06-16T16:29:14.602237Z",
    "container": "4c54683cec90500f329dfaad2e0856cc408483be0ae3166018121d4d4b9b3282",
    "container_config": {
        "Hostname": "78c72f8ba6ad",
        "User": "",
        "Memory": 0,
        "MemorySwap": 0,
        "CpuShares": 0,
        "AttachStdin": false,
        "AttachStdout": false,
        "AttachStderr": false,
        "PortSpecs": null,
        "Tty": false,
        "OpenStdin": false,
        "StdinOnce": false,
        "Env": null,
        "Cmd": [
            "/bin/sh",
            "-c",
            "#(nop) CMD [/bin/sh -c /bin/echo cmd | tee /tmp/cmd.log]"
        ],
        "Dns": null,
        "Image": "d10b6bd1321d45b0228b5741c01d1f76fd0288052e56836609f9bdf217854f3d",
        "Volumes": null,

# 引数でコマンドを指定せずに run を実行
# =&amp;gt; cmd で登録した内容が実行される

$ docker run 60671e99691
cmd
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;つまり、&lt;code&gt;RUN&lt;/code&gt; は &lt;code&gt;Dockerfile&lt;/code&gt; を元にビルドしているときに参照され、&lt;code&gt;CMD&lt;/code&gt; はコンテナを実行する際に参照されるということがわかる。パッケージをインストールしたりといった用途では通常 &lt;code&gt;RUN&lt;/code&gt; を使う。&lt;/p&gt;

&lt;h2 id="section-6"&gt;まとめ&lt;/h2&gt;

&lt;p&gt;仮想環境の発達でプログラマブルなインフラストラクチャーは実現できてきているけど、マシンを上げたり下げたりするのにどうしても時間がかかるし、それは仕方が無いものと我慢していた。&lt;code&gt;Docker&lt;/code&gt; を使ってみると、今までのそういった不満から解放されることができそう。一応開発中というステータスなのでプロダクション環境では使いづらいけど、開発やテスト、とくに構成管理ツールを設定するときなどは、この俊敏性、柔軟性は有効になると思う。&lt;/p&gt;

&lt;h2 id="section-7"&gt;参考&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href="http://docs.docker.io/en/latest/"&gt;Documentation&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

</content>
  </entry>
  <entry>
    <title>yum のパッケージキャッシュについて</title>
    <link rel="alternate" href="http://apatheia.info/blog/2013/06/16/yum-cache/"/>
    <id>http://apatheia.info/blog/2013/06/16/yum-cache/</id>
    <published>2013-06-16T01:26:00+09:00</published>
    <updated>2013-06-16T01:26:00+09:00</updated>
    <author>
      <name>f440</name>
    </author>
    <content type="html">&lt;p&gt;&lt;code&gt;/etc/yum.conf&lt;/code&gt;で&lt;code&gt;keepcache=1&lt;/code&gt;にしておくと、インストールしたパッケージがキャッシュされるようになる。これが無効化された状態だと、パッケージアップグレード時に問題が起きても元に戻せなくなるので有効化しておいた方がいい。&lt;/p&gt;



&lt;p&gt;あるパッケージについて、どのバージョンが利用可能な状態かは以下で確認できる。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ sudo yum --showduplicates list パッケージ名
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;RHEL なら過去のバージョンまですべて手に入るけど、CentOS だとOSリリース時のバージョンと最新版しか手に入らない模様。リポジトリ上なりキャッシュなりで過去のバージョンが手に入るのであれば、&lt;code&gt;yum install&lt;/code&gt; や &lt;code&gt;yum update&lt;/code&gt; は以下の手順でロールバックが行える。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# yum の利用履歴を確認
$ sudo yum history

# 履歴から詳細を確認
# 未引数なら直近、引数ありなら該当する ID を表示
$ sudo yum history info 4

# 仮に ID 4 で問題のバージョンアップが行われたようだということが確認できたら、その ID を指定して操作をアンドゥ
$ sudo yum history undo 4
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;アンドゥ(リドゥもある)では、対象パッケージおよび依存パッケージがまとめて一度に入れ替えられる。これはパッケージの操作がちゃんとトランザクションになっているため。&lt;/p&gt;

&lt;p&gt;話がそれるけど、パッケージの操作にトランザクションがかかるというのはかなり重要だ。たとえば syslog-ng から rsyslog に入れ替えるとき、単純にアンインストール、インストールの順番でやろうとするとアンインストールのタイミングで大量の Syslog 依存なパッケージが道連れになるけど、以下のようにすればひとつのトランザクションでパッケージを入れ替えることができる。(情報源: &lt;a href="http://wiki.rsyslog.com/index.php/Install_rsyslog_with_yum"&gt;Rsyslog Wiki&lt;/a&gt;)&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ sudo yum shell
&amp;gt; remove syslog-ng
&amp;gt; install rsyslog
&amp;gt; run
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;話がそれたついでにふれておくと、vagrant を使っているのであれば &lt;a href="https://github.com/fgrehm/vagrant-cachier"&gt;vagrant-cachier&lt;/a&gt; を使うとパッケージのキャッシュ保存先を仮想マシン外の領域(ホストOSとの共有ディスク部分など)に変更してくれる。こうすることで、仮想マシンを破棄してもパッケージのキャッシュが永続化されるため、2回目以降はダウンロードがスキップされて高速化する。&lt;/p&gt;

&lt;p&gt;話を戻すと、世の中何が起きるかわからないので古いパッケージもとっておいたほうがいいかと。ディスク容量が気になりだしたら、&lt;code&gt;yum clean packages&lt;/code&gt; を実行すればキャッシュは消せる。&lt;/p&gt;
</content>
  </entry>
</feed>
