<!DOCTYPE html><html><head><meta name="viewport" content="width=device-width"/><meta charSet="utf-8"/><title>イベント管理にSplunk Stormを使ってみる - aptheia.info</title><link rel="alternate" type="application/rss+xml" title="apatheia.info" href="/atom.xml"/><meta name="next-head-count" content="4"/><link rel="preload" href="/_next/static/css/3c128f59c2ecef969dbc.css" as="style"/><link rel="stylesheet" href="/_next/static/css/3c128f59c2ecef969dbc.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-a40ef1678bae11e696dba45124eadd70.js"></script><script src="/_next/static/chunks/webpack-1a8a258926ecde76681b.js" defer=""></script><script src="/_next/static/chunks/framework-895f067827ebe11ffe45.js" defer=""></script><script src="/_next/static/chunks/main-a9acf05574b3448968f1.js" defer=""></script><script src="/_next/static/chunks/pages/_app-d96712b144c157b4cbfa.js" defer=""></script><script src="/_next/static/chunks/915-c287d7adb8a31cf4da35.js" defer=""></script><script src="/_next/static/chunks/pages/blog/%5B...slug%5D-c134caf83809c687960e.js" defer=""></script><script src="/_next/static/PHKJ2Dzu0oDEBCrRGxDFE/_buildManifest.js" defer=""></script><script src="/_next/static/PHKJ2Dzu0oDEBCrRGxDFE/_ssgManifest.js" defer=""></script></head><body><div id="__next"><header><div id="site-title"><h1><a href="/">apatheia.info</a></h1></div><nav><ul><li><a href="/">Home</a></li><li><a href="/atom.xml">RSS</a></li></ul></nav></header><main><article><h1>イベント管理にSplunk Stormを使ってみる</h1><p id="article-info">Published on <!-- -->2013.03.17<!-- --> <span><a href="/blog/categories/logging/">logging</a> </span><span><a href="/blog/categories/visualization/">visualization</a> </span><span><a href="/blog/categories/splunk/">splunk</a> </span></p><div><p><a href="http://www.splunk.com/">Splunk</a> はおそらくイベント・ログ管理のツールとしてはおそらくもっとも有名で、日本でも販売展開しているので知っている人も多いかと思う。その splunk が <a href="https://www.splunkstorm.com/storm/">Splunk Storm</a> というサービスを始めている。試しに使ってみたのでその感想。</p>
<!-- more -->
<p>料金に応じて、格納可能なデータの容量が増える課金体系。無料でも1GBまで利用可能。</p>
<p>データの取り込みは以下の方法が提供されている:</p>
<ul>
<li>Syslog, Rsyslog, Syslog-ng などから転送</li>
<li>TCP/UDP を使って直接登録
<ul>
<li><code>cat some_file.log | nc endpoind_hostname port</code> で登録可能</li>
</ul>
</li>
<li>HTTP API</li>
<li>forwarder と呼ばれるクライアントプログラム
<ul>
<li>ログの読み取りなども可能</li>
</ul>
</li>
<li>ファイルアップロード</li>
</ul>
<p>試しにアカウントをとってApacheのログ形式のデータをncでがんがん取り込んでみたところ、1GB を超えたところでもうこれ以上追加できないとのメールが届いた。結果、200万件以上のデータが登録できていた。</p>
<p>複雑な検索式を使って特定の条件に合うレコードを弾き出したり、図示することができる。たとえば、ステータスコードでグルーピングしたグラフを表示するには、以下の検索式を指定する。</p>
<pre><code>sourcetype="access_combined" status="*" | timechart count by status
</code></pre>
<p>リアルタイムで計算しているらしく、新しい時間帯から古い時間帯へとどんどんグラフが追加されていく。</p>
<p><img src="/images/2013-03-17-logging-with-splunk-storm/httpstatus.png" alt="httpstatus"></p>
<p>さすがというか、よくできている。</p>
</div></article></main><footer><ul><li>Link:</li><li><a href="https://twitter.com/f440">Twitter</a></li><li><a href="https://github.com/f440">Github</a></li><li><a href="https://pinbaord.in/u:f440">Pinbaord</a></li></ul></footer></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"localPath":"/home/f440/go/src/github.com/f440/f440.github.com/content/2013-03-17-logging-with-splunk-storm.markdown","path":"2013/03/17/logging-with-splunk-storm","layout":"post","title":"イベント管理にSplunk Stormを使ってみる","createdAt":"2013-03-17T12:17:00.000Z","kind":"article","comments":true,"tags":["logging","visualization","splunk"],"content":"\u003cp\u003e\u003ca href=\"http://www.splunk.com/\"\u003eSplunk\u003c/a\u003e はおそらくイベント・ログ管理のツールとしてはおそらくもっとも有名で、日本でも販売展開しているので知っている人も多いかと思う。その splunk が \u003ca href=\"https://www.splunkstorm.com/storm/\"\u003eSplunk Storm\u003c/a\u003e というサービスを始めている。試しに使ってみたのでその感想。\u003c/p\u003e\n\u003c!-- more --\u003e\n\u003cp\u003e料金に応じて、格納可能なデータの容量が増える課金体系。無料でも1GBまで利用可能。\u003c/p\u003e\n\u003cp\u003eデータの取り込みは以下の方法が提供されている:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eSyslog, Rsyslog, Syslog-ng などから転送\u003c/li\u003e\n\u003cli\u003eTCP/UDP を使って直接登録\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003ecat some_file.log | nc endpoind_hostname port\u003c/code\u003e で登録可能\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eHTTP API\u003c/li\u003e\n\u003cli\u003eforwarder と呼ばれるクライアントプログラム\n\u003cul\u003e\n\u003cli\u003eログの読み取りなども可能\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eファイルアップロード\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e試しにアカウントをとってApacheのログ形式のデータをncでがんがん取り込んでみたところ、1GB を超えたところでもうこれ以上追加できないとのメールが届いた。結果、200万件以上のデータが登録できていた。\u003c/p\u003e\n\u003cp\u003e複雑な検索式を使って特定の条件に合うレコードを弾き出したり、図示することができる。たとえば、ステータスコードでグルーピングしたグラフを表示するには、以下の検索式を指定する。\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003esourcetype=\"access_combined\" status=\"*\" | timechart count by status\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eリアルタイムで計算しているらしく、新しい時間帯から古い時間帯へとどんどんグラフが追加されていく。\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/2013-03-17-logging-with-splunk-storm/httpstatus.png\" alt=\"httpstatus\"\u003e\u003c/p\u003e\n\u003cp\u003eさすがというか、よくできている。\u003c/p\u003e\n"}},"__N_SSG":true},"page":"/blog/[...slug]","query":{"slug":["2013","03","17","logging-with-splunk-storm"]},"buildId":"PHKJ2Dzu0oDEBCrRGxDFE","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>